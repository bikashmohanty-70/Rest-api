<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Red Hat OpenShift 4.2 IPI on OpenStack 13: All-in-one setup</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yPfQWPtfzAk/" /><category term="Containers" /><category term="DevOps" /><category term="Performance" /><category term="bare metal" /><category term="openshift" /><category term="OpenStack" /><category term="provisioning" /><category term="RHEL" /><author><name>Michele Naldini</name></author><id>https://developers.redhat.com/blog/?p=656047</id><updated>2020-02-06T08:00:29Z</updated><published>2020-02-06T08:00:29Z</published><content type="html">&lt;p&gt;Months ago, a customer asked me about &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; on OpenStack, especially regarding the network configuration options available in OpenShift at the node level. In order to give them an answer and increase my confidence on $topic, I&amp;#8217;ve considered how to test this scenario.&lt;/p&gt; &lt;p&gt;At the same time, the Italian solution architect &amp;#8220;Top Gun Team&amp;#8221; was in charge of preparing speeches and demos for the Italian Red Hat Forum (also known as Open Source Day) for the Rome and Milan dates. Brainstorming led me to start my journey toward testing OpenShift 4.2 setup on OpenStack 13 in order to reply to the customer and leverage this effort to build a demo video for Red Hat Forum.&lt;/p&gt; &lt;p&gt;&lt;span id="more-656047"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you want to skip the bits and bytes, skip ahead to the &amp;#8220;Demo&amp;#8221; section.&lt;/p&gt; &lt;h2&gt;OpenShift 4.2 on OpenStack 13: Background&lt;/h2&gt; &lt;p&gt;Why OpenShift on OpenStack? There are a number of advantages to combining these two solutions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;OpenStack provides OpenShift with a top-class private cloud architecture&lt;/strong&gt; to host OpenShift nodes, granting multi-tenancy, an as-a-service approach, and modularity at the Infrastructure-as-a-Service (IaaS) level.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;This combination provides a three-layer scaling architecture&lt;/strong&gt; because OpenStack nodes, OpenShift nodes, and OpenShift pods can be scaled horizontally. This combination means that you can follow your business needs without constraints.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenStack provides a programmatic API-driven approach&lt;/strong&gt; for OpenShift. For instance, you can scale your OpenShift worker nodes via MachineSet by calling the OpenStack API with a single click.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenShift on OpenStack is integrated&lt;/strong&gt; with Nova, Cinder, Swift, Octavia, Kuryr, etc. For instance, with Kuryr you can avoid double encapsulation—i.e., OpenShift software-defined networking (SDN) on OpenStack SDN—by using Neutron networks at the pod level.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;OpenShift on OpenStack is co-engineered by Red Hat&lt;/strong&gt;, which means having aligned product roadmaps and integration tests created by the Red Hat engineers working on these projects every single day.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;OpenShift Installer Provisioned Infrastructure (IPI) was released with OpenShift 4.2. The objectives for the new installer are to provision and configure OpenShift 4.2 in a fully automated and opinionated way, making it easy to get started on day one and granting you more time to focus on your team on day two.&lt;/p&gt; &lt;p&gt;As you may know, IPI on OpenShift 4.2 also supports &lt;a href="https://www.redhat.com/en/technologies/linux-platforms/openstack-platform" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenStack Platform&lt;/a&gt; 13 as a provider, leveraging OpenStack&amp;#8217;s virtualization capabilities to host OpenShift nodes. The main concern to me was that I didn&amp;#8217;t have enough bare-metal nodes to build my environment. A standard high-availability (HA) OpenStack environment is composed of:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;One director node&lt;/li&gt; &lt;li&gt;Three controllers&lt;/li&gt; &lt;li&gt;Three Ceph nodes&lt;/li&gt; &lt;li&gt;At least two compute nodes&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;My goal was to build the following to host OpenShift 4.2 and simulate an HA environment at the control plane and storage level:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;One director node (undercloud)&lt;/li&gt; &lt;li&gt;Three controllers&lt;/li&gt; &lt;li&gt;Three Ceph nodes&lt;/li&gt; &lt;li&gt;One compute node (overcloud)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;em&gt;Why?&lt;/em&gt; To simulate the existing customer environment.&lt;/p&gt; &lt;p&gt;&lt;em&gt;How?&lt;/em&gt; Using VMs as OpenStack nodes.&lt;/p&gt; &lt;p&gt;I had an idea: To see if I can set up everything with just a single bare metal server. That effort pushed me to publish this article so I can share and explain how I tested an OpenShift 4.2 IPI setup on OpenStack 13 with a single Red Hat Enterprise Linux (RHEL) server. Doing this was possible because RHEL is properly tuned to use nested virtualization with KVM.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Warning:&lt;/strong&gt; This article was written to help customers, partners, and community members test OpenShift 4.2 on OpenStack 13 only for demo/test purposes. This procedure and the resulting architecture &lt;em&gt;are not supported&lt;/em&gt; (and not even suggested) by Red Hat.&lt;/p&gt; &lt;p&gt;I&amp;#8217;d like to thank Daniel Bellantuono for sharing helpful tips about OpenStack&amp;#8217;s architecture.&lt;/p&gt; &lt;h2&gt;Scenario&lt;/h2&gt; &lt;p&gt;I used just a single bare-metal node (L0) and then, using KVM&amp;#8217;s nested virtualization features, created a deployment of OpenStack nodes (L1) with virtualized OpenShift nodes (L2) on top. Figure one shows a schema summarizing the whole setup.&lt;/p&gt; &lt;div id="attachment_676897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e2729a74a7f0.png"&gt;&lt;img aria-describedby="caption-attachment-676897" class="wp-image-676897" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e2729a74a7f0.png" alt="The full OpenShift 4.2 on OpenStack 13 all-in-one schema." width="640" height="519" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e2729a74a7f0.png 813w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e2729a74a7f0-300x243.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e2729a74a7f0-768x623.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-676897" class="wp-caption-text"&gt;Figure 1: The resulting schema.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Now, let&amp;#8217;s dig into the different layers.&lt;/p&gt; &lt;h2&gt;L0 bare metal&lt;/h2&gt; &lt;p&gt;The L0 bare metal node was configured with Red Hat Enterprise Linux and KVM to act as a hypervisor. Its server requirements are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;At least 32 cores&lt;/li&gt; &lt;li&gt;160 GB RAM&lt;/li&gt; &lt;li&gt;500 GB SSD disk (to host high-performance VM disks, namely the Ceph OSD disks, and the Nova compute disk)&lt;/li&gt; &lt;li&gt;200 GB SAS disk (to host medium-performance VM disks, namely the undercloud disk and the controller disks).&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; You could use SSDs for every VM, but I had to balance my needs with hardware availability.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;virsh&lt;/code&gt; command shows the rest of the bare metal node&amp;#8217;s specs:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# virsh nodeinfo CPU model: x86_64 CPU(s): 32 CPU frequency: 2099 MHz CPU socket(s): 1 Core(s) per socket: 8 Thread(s) per core: 2 NUMA cell(s): 2 Memory size: 167676348 KiB&lt;/pre&gt; &lt;p&gt;Next, I used the &lt;code&gt;tuned&lt;/code&gt; command to perform network latency workload tuning at the L0 level:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# tuned-adm profile network-latency&lt;/pre&gt; &lt;p&gt;In order to successfully configure and deploy your overcloud nodes, you need to do two things. First, you need to define a provisioning network on libvirt for the undercloud to use when installing our overcloud nodes via PXE. Second, you have to define your virtual machines.&lt;/p&gt; &lt;p&gt;Here is a snippet of network config at the L0 level:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# cat &amp;#62; /tmp/provisioning.xml &amp;#60;&amp;#60;EOF &amp;#60;network&amp;#62; &amp;#60;name&amp;#62;provisioning&amp;#60;/name&amp;#62; &amp;#60;ip address="172.16.0.254" netmask="255.255.255.0"/&amp;#62; &amp;#60;/network&amp;#62; EOF [root@newkvm ~]# echo "Defining provisioning network..." [root@newkvm ~]# virsh net-define /tmp/provisioning.xml [root@newkvm ~]# echo "Setting net-autostart to provisioning network..." [root@newkvm ~]# virsh net-autostart provisioning [root@newkvm ~]# echo "Starting provisioning network..." [root@newkvm ~]# virsh net-start provisioning [root@newkvm ~]# echo "Disabling DHCP on default network..." [root@newkvm ~]# if(virsh net-dumpxml default | grep dhcp &amp;#38;&amp;#62;/dev/null); then virsh net-update default delete ip-dhcp-range "&amp;#60;range start='192.168.122.2' end='192.168.122.254'/&amp;#62;" --live --config echoinfo "DHCP already disabled, skipping"&lt;/pre&gt; &lt;p&gt;The provisioning network is usually a pre-existing datacenter network in a native VLAN configuration. This configuration is used by the undercloud to perform node introspection and setup via PXE and TFTP. For this reason, I created a dedicated network called &amp;#8220;provisioning&amp;#8221; (Figure 1&amp;#8217;s blue section) to attach to all of my VMs.&lt;/p&gt; &lt;p&gt;As you may already know, the entire OS setup and configuration for OpenStack nodes (VMs in our case) is managed by the Red Hat OpenStack Platform director. In addition, DHCP was disabled on the default (pre-existing) libvirt network because the director assigns IPs during OpenStack setup. Last, but not least, we need to configure our hypervisor to use an Ironic project driver. My choice was to use VirtualBMC to simulate Intelligent Platform Management Interfaces (IPMIs) that are not available in a virtual machine environment.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;a href="https://access.redhat.com/solutions/3057171" target="_blank" rel="noopener noreferrer"&gt;Read this Red Hat Knowledge Base&lt;/a&gt; article to learn more about how to configure VBMC and use it to import and introspect bare metal nodes.&lt;/p&gt; &lt;p&gt;I don&amp;#8217;t want to go deeper into the details of OpenStack setup because the process is long and difficult to summarize. This article assumes that you have a basic knowledge and understanding of OpenStack architecture. That being said, some basic steps are provided.&lt;/p&gt; &lt;h2&gt;L1 virtual machines (OpenStack nodes)&lt;/h2&gt; &lt;p&gt;VMs were defined using &lt;code&gt;qemu-img&lt;/code&gt;, &lt;code&gt;virt-customize&lt;/code&gt;, and &lt;code&gt;virt-install&lt;/code&gt; starting from the Red Hat Enterprise Linux 7 KVM guest image downloadable from the Red Hat Customer Portal:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# echo "Downloading basic RHEL image" [root@newkvm ~]# curl -o rhel7-guest-official.qcow2 $RHEL_IMAGE_U [root@newkvm ~]# echo "Cloning RHEL image to a 100G sparse image..." [root@newkvm ~]# qemu-img create -f qcow2 rhel7-guest.qcow2 100G [root@newkvm ~]# echo "Extending file system..." [root@newkvm ~]# virt-resize --expand /dev/sda1 rhel7-guest-official.qcow2 rhel7-guest.qcow2 [root@newkvm ~]# echo "Checking image filesystem size..." [root@newkvm ~]# virt-filesystems --long -h -a rhel7-guest.qcow2 | grep 100G &amp;#38;&amp;#62; /dev/null [root@newkvm ~]# echo "Deleting old image..." [root@newkvm ~]# rm -f rhel7-guest-official.qcow2 [root@newkvm ~]# echo "Create undercloud qcow2 disk..." [root@newkvm ~]# qemu-img create -f qcow2 -b rhel7-guest.qcow2 undercloud.qcow2&lt;/pre&gt; &lt;p&gt;Director needs to have two NICs. The first one (eth0) is attached to the &lt;em&gt;provisioning network&lt;/em&gt; in order to successfully deploy overcloud nodes, and the second (eth1) is attached to the &lt;em&gt;default network&lt;/em&gt; in order to reach (via the NAT made by the L0 hypervisor) the internet to download the RPM packages needed for the setup:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# echo "Customizing VM..." [root@newkvm ~]# virt-customize -a undercloud.qcow2 --root-password password:mypassword --ssh-inject "root:file:/root/.ssh/id_rsa.pub" --selinux-relabel --run-command 'yum remove cloud-init* -y &amp;#38;&amp;#38; cp /etc/sysconfig/network-scripts/ifcfg-eth{0,1} &amp;#38;&amp;#38; sed -i s/ONBOOT=.*/ONBOOT=no/g /etc/sysconfig/network-scripts/ifcfg-eth0 &amp;#38;&amp;#38; cat &amp;#60;&amp;#60; EOF &amp;#62; /etc/sysconfig/network-scripts/ifcfg-eth1 DEVICE=eth1 ONBOOT=yes IPADDR=192.168.122.253 NETMASK=255.255.255.0 GATEWAY=192.168.122.1 NM_CONTROLLED=no DNS1=192.168.122.1 EOF' [root@newkvm ~]# echo "Creating undercloud VM" [root@newkvm ~]# virt-install --ram 12288 --vcpus 8  --os-variant rhel7 \ --disk path=/var/lib/libvirt/images/undercloud.qcow2,device=disk,bus=virtio,format=qcow2 \ --import --noautoconsole --vnc &lt;strong&gt;--network network:provisioning&lt;/strong&gt; \ &lt;strong&gt;--network network:default&lt;/strong&gt; --name undercloud  [root@newkvm ~]# echo "Start undercloud VM now and on-boot" [root@newkvm ~]# virsh start undercloud [root@newkvm ~]# virsh autostart undercloud&lt;/pre&gt; &lt;p&gt;The setup for other VMs is similar, with the only difference being the amount of resources involved (such as RAM and CPU) and the NIC configuration. For the overcloud nodes, I added two additional NICs (Figure 1&amp;#8217;s orange section) because I wanted a bond inside Open vSwitch. Within this bond, I configured the OpenStack networks (namely InternalApi, Tenant Network, Storage, and Storage Management) with the tag &lt;code&gt;vlan&lt;/code&gt; and left the external network untagged. As a result, our external network on the OpenStack side will use the default network on the L0 hypervisor.&lt;/p&gt; &lt;p&gt;After this basic setup, I installed the undercloud, imported and introspected the OpenStack nodes, and then built my OSP templates to successfully deploy my overcloud:&lt;/p&gt; &lt;div id="attachment_677577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e28195f7c158.png"&gt;&lt;img aria-describedby="caption-attachment-677577" class="wp-image-677577 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e28195f7c158-1024x342.png" alt="The output from building the OSP templates" width="640" height="214" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e28195f7c158-1024x342.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e28195f7c158-300x100.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e28195f7c158-768x257.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-677577" class="wp-caption-text"&gt;Figure 2: Building the OSP templates.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I skipped the overcloud endpoint TLS configuration because, at the time of this writing, Red Hat OpenShift Container Platform 4.2 cannot be installed via Installer Provisioned Installation (IPI) on Red Hat OpenStack Platform when the endpoints are encrypted with self-signed certificates (as highlighted in &lt;a href="https://access.redhat.com/solutions/4735631" target="_blank" rel="noopener noreferrer"&gt;this knowledge base&lt;/a&gt; entry). Therefore, the results are this:&lt;/p&gt; &lt;pre&gt;[root@newkvm ~]# virsh list --all Id Name State ---------------------------------------------------- 17 undercloud running 18 overcloud-ceph01 running 19 overcloud-ceph02 running 20 overcloud-ceph03 running 21 overcloud-compute01 running 22 overcloud-ctrl01 running 23 overcloud-ctrl02 running 24 overcloud-ctrl03 running&lt;/pre&gt; &lt;p&gt;Here is the resulting overcloud server list:&lt;/p&gt; &lt;pre&gt;(undercloud) [stack@undercloud ~]$ openstack server list +--------------------------------------+------------------+--------+----------------------+----------------+--------------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+------------------+--------+----------------------+----------------+--------------+ | 9c4d82fd-c37e-4341-9a24-ea6416751aa3 | lab-controller01 | ACTIVE | ctlplane=172.16.0.40 | overcloud-full | control | | ae2431d5-ff70-4fd3-83e3-48c72fca626e | lab-controller03 | ACTIVE | ctlplane=172.16.0.21 | overcloud-full | control | | 4176914d-23ef-4e5f-83cd-86a53d320fc4 | lab-controller02 | ACTIVE | ctlplane=172.16.0.29 | overcloud-full | control | | 78e6d4b0-c3de-431d-b144-6aa19664818d | lab-ceph01 | ACTIVE | ctlplane=172.16.0.46 | overcloud-full | ceph-storage | | b7bb7596-4bf7-45f7-bd3b-c6bb79304531 | lab-ceph02 | ACTIVE | ctlplane=172.16.0.22 | overcloud-full | ceph-storage | | 35258a3a-ff8b-44d0-b68b-a55039c4451d | lab-compute01 | ACTIVE | ctlplane=172.16.0.26 | overcloud-full | compute | | 93d7ff6c-4713-431e-9461-0303126eb7ad | lab-ceph03 | ACTIVE | ctlplane=172.16.0.37 | overcloud-full | ceph-storage | +--------------------------------------+------------------+--------+----------------------+----------------+--------------+&lt;/pre&gt; &lt;p&gt;Because of the limited hardware capabilities (and over-committing, too, given that we are talking about one single bare-metal server), I executed many tests in order to successfully deploy OpenShift on OpenStack. I ran into many timeout issues but finally, I found the right tuning to apply. What follows are a couple of tips and tricks regarding OpenStack compute node timeout tuning.&lt;/p&gt; &lt;p&gt;You probably had to make two edits in the &lt;code&gt;nova_libvirt&lt;/code&gt; container configuration file &lt;code&gt;(/var/lib/config-data/puppet-generated/nova_libvirt/etc/nova/nova.conf)&lt;/code&gt;. The first is in the &lt;code&gt;[neutron]&lt;/code&gt; section, setting a timeout value (in my case 300 seconds) big enough to avoid timeouts on the Neutron side when nova spawns a new instance:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;[neutron] url=http://172.17.1.150:9696 ovs_bridge=br-int default_floating_pool=nova extension_sync_interval=600 &lt;strong&gt;timeout=300&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;The second is in the  &lt;code&gt;[default]&lt;/code&gt; section, setting a timeout value (in my case 300 seconds) big enough to avoid timeouts on the Neutron side when nova tries to attach a Virtual Interface (VIF) to a new instance:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;[default] instance_usage_audit_period=hour rootwrap_config=/etc/nova/rootwrap.conf compute_driver=libvirt.LibvirtDriver allow_resize_to_same_host=False vif_plugging_is_fatal=True &lt;strong&gt;vif_plugging_timeout=300&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;After these edits, you would restart the &lt;code&gt;nova_libvirt&lt;/code&gt; container on the compute node.&lt;/p&gt; &lt;p&gt;Be aware that these changes are applied to the OpenStack Nova container after a container restart. If you want to redeploy your overcloud later, you&amp;#8217;ll have to customize &lt;code&gt;nova.conf&lt;/code&gt; via a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13/html/advanced_overcloud_customization/chap-configuration_hooks#sect-Customizing_Overcloud_PreConfiguration" target="_blank" rel="noopener noreferrer"&gt;custom puppet configuration&lt;/a&gt; executed by OpenStack director.&lt;/p&gt; &lt;h2&gt;L2 nested virtual machines (OpenShift nodes)&lt;/h2&gt; &lt;p&gt;In addition to those nodes (VMs in my case), I of course had to consider the list of requirements needed by IPI in terms of vCPU, RAM, floating IPs, and the security groups to be available at the tenant level. The full prerequisites for OpenShift 4.2 IPI on OpenStack are available &lt;a href="https://docs.openshift.com/container-platform/4.2/installing/installing_openstack/installing-openstack-installer-custom.html#installation-osp-default-deployment_installing-openstack-installer-custom" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Because I&amp;#8217;ve tested the setup many times and I didn&amp;#8217;t want to worry about prerequisites every time I executed a setup, I made a simple bash script to prepare my tenant on OpenStack:&lt;/p&gt; &lt;pre&gt;[stack@undercloud osd-ocp-demo]$ cat create_ocp_tenant.sh #!/bin/bash source ../overcloudrc openstack project create ocp-tenant openstack user create ocp-user --password mypassword user=$(openstack user show ocp-user -f value -c id) admin=$(openstack user show admin -f value -c id) project=$(openstack project show ocp-tenant -f value -c id) openstack role add --user $user --project $project _member_ openstack role add --user $user --project $project admin openstack role add --user $admin --project $project admin openstack role add --user $user --project $project swiftoperator # show default quota and set new limits on project ocp-tenant echo "compute quota" openstack quota list --compute --project ocp-tenant -f yaml openstack quota set --cores 40 --ram 102400 $project echo "network quota" openstack quota list --network --project ocp-tenant -f yaml openstack quota set --secgroups 40 --secgroup-rules 500 $project # create needed flavors openstack flavor create --ram 16384 --vcpu 4 --disk 25 master echo -e "working on $project" source ocp-tenant-openrc openstack object store account set --property Temp-URL-Key=superkey # create rhcos image curl --compressed -J -L -o rhcos-openstack.qcow2 https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos/pre-release/latest/rhcos-42.80.20191002.0-openstack.qcow2 openstack image create --container-format=bare --disk-format=qcow2 --file rhcos-openstack.qcow2 rhcos mkdir -p /home/stack/osd-ocp-demo cd /home/stack/osd-ocp-demo cat &amp;#60;&amp;#60;EOF &amp;#62; clouds.yaml clouds: openstack: auth: auth_url: http://192.168.122.150:5000/v3 username: "ocp-user" password: "mypassword" project_id: $project project_name: "ocp-tenant" user_domain_name: "Default" region_name: "regionOne" interface: "public" identity_api_version: 3 EOF wget -r --no-parent -A 'openshift-install-linux*.tar.gz' https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/ wget -r --no-parent -A 'openshift-client-linux*.tar.gz' https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/ tar -xvzf mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-install-linux-4.2.4.tar.gz -C . tar -xvzf mirror.openshift.com/pub/openshift-v4/clients/ocp/latest/openshift-client-linux-4.2.0.tar.gz -C . # openstack FIP for API lb openstack floating ip create --floating-ip-address 192.168.122.164 --project ocp-tenant external # openstack FIP for APPS lb openstack floating ip create --floating-ip-address 192.168.122.180 --project ocp-tenant external # add ssh key to ssh agent eval "$(ssh-agent -s)" ssh-add /home/stack/.ssh/id_rsa # configure KUBECONFIG path export KUBECONFIG='/home/stack/osd-ocp-demo/auth/kubeconfig'&lt;/pre&gt; &lt;p&gt;Now that the prerequisites are here, let us look at our &lt;code&gt;install-config.yam&lt;/code&gt; file, which will instruct the IPI installer about OpenShift configuration in terms of the number of nodes, flavor to be used, network CIDR, etc.&lt;/p&gt; &lt;p&gt;As you can see, I specified fields to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Build two worker nodes.&lt;/li&gt; &lt;li&gt;Build three master nodes.&lt;/li&gt; &lt;li&gt;Use OpenStack as the provider with the flavor &amp;#8220;master&amp;#8221; (created by the script &lt;code&gt;create_ocp_tenant.sh)&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In addition, I included a floating IP (FIP) for the internal API load balancer (&lt;code&gt;lbFloatingIP&lt;/code&gt;)—this FIP grants access to the internal LB (API load balancer):&lt;/p&gt; &lt;pre&gt;(undercloud) [stack@undercloud osd-ocp-demo-static-nic]$ cat template/install-config.yaml apiVersion: v1 clusterID: ocp4 baseDomain: osd2019.local compute: - hyperthreading: Enabled &lt;strong&gt;name: worker&lt;/strong&gt; platform: {} &lt;strong&gt;replicas: 2&lt;/strong&gt; type: worker controlPlane: hyperthreading: Enabled &lt;strong&gt;name: master&lt;/strong&gt; platform: {} &lt;strong&gt;replicas: 3&lt;/strong&gt; type: master metadata: name: ocp4 networking: clusterNetwork: - cidr: 10.128.0.0/14 hostPrefix: 23 machineCIDR: 10.0.0.0/16 networkType: OpenShiftSDN serviceNetwork: - 172.60.0.0/16 platform: openstack: &lt;strong&gt;cloud: openstack&lt;/strong&gt; computeFlavor: master externalNetwork: external &lt;strong&gt;lbFloatingIP: 192.168.122.164&lt;/strong&gt; &lt;strong&gt;octaviaSupport: false&lt;/strong&gt; region: regionOne trunkSupport: false pullSecret: 'mypull secret' sshKey: ssh-rsa blablabla stack@undercloud.redhat.local&lt;/pre&gt; &lt;p&gt;You may also notice that I didn&amp;#8217;t use Octavia (an OpenStack load balancer-as-a-service) because, in my own test, I specifically want to simulate a customer environment where Octavia is not used. Octavia is &lt;em&gt;not&lt;/em&gt; a strict requirement unless you are using Kuryr.&lt;/p&gt; &lt;p&gt;We can now execute the installation with a simple command (if you want, you can specify the debug log level in order to have a better understanding of the installation process):&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo]$ ./openshift-install create cluster --log-level debug DEBUG OpenShift Installer v4.2.4 DEBUG Built from commit 425e4ff0037487e32571258640b39f56d5ee5572 DEBUG Fetching "Terraform Variables"... DEBUG Loading "Terraform Variables"... DEBUG Loading "Cluster ID"... DEBUG Loading "Install Config"... DEBUG Loading "SSH Key"... DEBUG Loading "Base Domain"... DEBUG Loading "Platform"... DEBUG Loading "Cluster Name"... DEBUG Loading "Base Domain"... DEBUG Loading "Pull Secret"... DEBUG Loading "Platform"... DEBUG Using "Install Config" loaded from target directory DEBUG Loading "Install Config"... DEBUG Loading "Image"... DEBUG Loading "Install Config"... DEBUG Loading "BootstrapImage"... DEBUG Loading "Install Config"... DEBUG Loading "Bootstrap Ignition Config"... DEBUG Loading "Install Config"... DEBUG Loading "Kubeconfig Admin Client"... DEBUG Loading "Certificate (admin-kubeconfig-client)"... DEBUG Loading "Certificate (admin-kubeconfig-signer)"... DEBUG Loading "Certificate (kube-apiserver-complete-server-ca-bundle)"... DEBUG Loading "Certificate (kube-apiserver-localhost-ca-bundle)"... OUTPUT TRUNCATED&lt;/pre&gt; &lt;p&gt;During the installation, log into the OpenStack dashboard (shown in Figure 3) and you&amp;#8217;ll see that OpenShift IPI takes care of everything; from spawning new instances, to building a dedicated tenant network, configuring security groups, and so on so forth.&lt;/p&gt; &lt;div id="attachment_677587" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281995be9d4.png"&gt;&lt;img aria-describedby="caption-attachment-677587" class="wp-image-677587 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281995be9d4-1024x514.png" alt="The OpenStack dashboard showing the Project -&amp;#62; Compute -&amp;#62; Instances screen." width="640" height="321" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281995be9d4-1024x514.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281995be9d4-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281995be9d4-768x385.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-677587" class="wp-caption-text"&gt;Figure 3: The OpenStack dashboard lets you watch the installation process in action.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;After a while (about 30 minutes) you&amp;#8217;ll have your Red Hat OpenShift 4.2 cluster up and running, as you can see here:&lt;/p&gt; &lt;pre&gt;DEBUG Still waiting for the cluster to initialize: Working towards 4.2.4: 98% complete DEBUG Still waiting for the cluster to initialize: Working towards 4.2.4: 99% complete DEBUG Cluster is initialized INFO Waiting up to 10m0s for the openshift-console route to be created... DEBUG Route found in openshift-console namespace: console DEBUG Route found in openshift-console namespace: downloads DEBUG OpenShift console route is created INFO Install complete! &lt;strong&gt;INFO To access the cluster as the system:admin user when using 'oc', run 'export KUBECONFIG=/home/stack/osd-ocp-demo/auth/kubeconfig'&lt;/strong&gt; &lt;strong&gt;INFO Access the OpenShift web-console here: https://console-openshift-console.apps.ocp4.osd2019.local&lt;/strong&gt; &lt;strong&gt;INFO Login to the console with user: kubeadmin, password: YOURKUBEADMINRANDOMPASSWORD&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;Looking at OpenStack network topology in Figure 4, you&amp;#8217;ll see the resulting architecture.&lt;/p&gt; &lt;div id="attachment_677607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a04ee758.png"&gt;&lt;img aria-describedby="caption-attachment-677607" class="wp-image-677607 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a04ee758-1024x446.png" alt="The OpenStack dashboard displaying Project -&amp;#62; Network -&amp;#62; Network Toplogy." width="640" height="279" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a04ee758-1024x446.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a04ee758-300x131.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a04ee758-768x334.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-677607" class="wp-caption-text"&gt;Figure 4: Your OpenStack network topology.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can also use the &lt;code&gt;oc&lt;/code&gt; client from the client machine used to install OpenShift (in my case, it was my undercloud VM):&lt;/p&gt; &lt;pre&gt;(undercloud) [stack@undercloud osd-ocp-demo$ oc get nodes NAME STATUS ROLES AGE VERSION ocp4-4p5fd-master-0 Ready master 9d v1.14.6+c7d2111b9 ocp4-4p5fd-master-1 Ready master 9d v1.14.6+c7d2111b9 ocp4-4p5fd-master-2 Ready master 9d v1.14.6+c7d2111b9 ocp4-4p5fd-worker-76gvc Ready worker 9d v1.14.6+c7d2111b9 ocp4-4p5fd-worker-n6jvq Ready worker 9d v1.14.6+c7d2111b9&lt;/pre&gt; &lt;p&gt;There is only one post-deployment command required in order to attach a pre-allocated floating IP address (FIP) to the Ingress port. Details can be found in the official docs &lt;a href="https://docs.openshift.com/container-platform/4.2/installing/installing_openstack/installing-openstack-installer-custom.html#installation-osp-configuring-api-floating-ip_installing-openstack-installer-custom" target="_blank" rel="noopener noreferrer"&gt;here&lt;/a&gt;. This step is needed because the IPI installer takes care of configuring a Keepalived pod on every master and worker, exposing the virtual IPs (VIPs) that route traffic to internal APIs, the Ingress, and DNS services.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s assign our FIP in order to reach the OpenShift console. We need to assign it to the &lt;code&gt;ingress-port&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo]$ openstack port show c3c14e9d-750f-46fb-af9c-e9fd375719b2 +-----------------------+-------------------------------------------------------------------------+ | Field | Value | +-----------------------+-------------------------------------------------------------------------+ | admin_state_up | UP | | allowed_address_pairs | | | binding_host_id | | | binding_profile | | | binding_vif_details | | | binding_vif_type | unbound | | binding_vnic_type | normal | | created_at | 2019-11-01T00:49:21Z | | data_plane_status | None | | description | | | device_id | | | device_owner | | | dns_assignment | None | | dns_name | None | | extra_dhcp_opts | | | fixed_ips | ip_address='10.0.0.7', subnet_id='9cbfdd62-b1e5-4f01-b49c-db992b9afc8e' | | id | &lt;strong&gt;c3c14e9d-750f-46fb-af9c-e9fd375719b2&lt;/strong&gt; | | ip_address | None | | mac_address | fa:16:3e:b8:39:8b | &lt;strong&gt;| name | ocp4-ll4qz-ingress-port |&lt;/strong&gt; | network_id | ec5de4de-2f52-42c5-87bf-35c8d91bd1a7 | | option_name | None | | option_value | None | | port_security_enabled | True | | project_id | 699eeaefb7b84291a75d389ec0f10ea2 | | qos_policy_id | None | | revision_number | 7 | | security_group_ids | 9e6ee5d9-fa19-418c-804e-f1c654d2e34b | | status | DOWN | | subnet_id | None | | tags | openshiftClusterID=ocp4-ll4qz | | trunk_details | None | | updated_at | 2019-11-01T00:49:29Z | +-----------------------+-------------------------------------------------------------------------+ &lt;strong&gt;openstack floating ip set --port c3c14e9d-750f-46fb-af9c-e9fd375719b2 192.168.122.180&lt;/strong&gt;&lt;/pre&gt; &lt;p&gt;Finally, I updated my host file in order to reach OpenShift via FQDN so I didn&amp;#8217;t have to configure a DNS service:&lt;/p&gt; &lt;pre&gt;#ocp4 192.168.122.164 api.ocp4.osd2019.local 192.168.122.180 console-openshift-console.apps.ocp4.osd2019.local 192.168.122.180 integrated-oauth-server-openshift-authentication.apps.ocp4.osd2019.local 192.168.122.180 oauth-openshift.apps.ocp4.osd2019.local 192.168.122.180 prometheus-k8s-openshift-monitoring.apps.ocp4.osd2019.local 192.168.122.180 grafana-openshift-monitoring.apps.ocp4.osd2019.local&lt;/pre&gt; &lt;p&gt;That&amp;#8217;s it. Thirty minutes later, you&amp;#8217;ll have your OpenShift cluster up and running on OpenStack. You can then start playing around to test the capabilities this environment can grant to your organization. See Figure 5 for the results in the Red Hat OpenShift Container Platform.&lt;/p&gt; &lt;div id="attachment_677627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a44b51c1.png"&gt;&lt;img aria-describedby="caption-attachment-677627" class="wp-image-677627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a44b51c1-1024x559.png" alt="Red Hat OpenShift Container Platform's dashboard." width="640" height="349" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a44b51c1-1024x559.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a44b51c1-300x164.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/img_5e281a44b51c1-768x419.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-677627" class="wp-caption-text"&gt;Figure 5: Your new cluster in Red Hat OpenShift Container Platform.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Networking deep dive&lt;/h2&gt; &lt;p&gt;As you saw, we preallocated two FIPs within our tenant using the bash script I shared in the section &amp;#8220;L2 nested virtual machines (OpenShift nodes),&amp;#8221; in the lines:&lt;/p&gt; &lt;pre&gt;lbFloatingIP: 192.168.122.164 ingress port floating: 192.168.122.180&lt;/pre&gt; &lt;p&gt;These two FIPS are associated with two Neutron ports, namely &lt;code&gt;api-port&lt;/code&gt; (internal IP 10.0.0.5) and the Ingress port (internal IP 10.0.0.7). The first FIP assignment (192.168.122.164 -&amp;#62; 10.0.0.5) was made automatically by IPI during setup. The second FIP association is, instead, managed by us as we saw previously in order to reach OpenShift console and other services:&lt;/p&gt; &lt;pre&gt;overcloud) [stack@undercloud osd-ocp]$ openstack floating ip list +--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+ | ID | Floating IP Address | Fixed IP Address | Port | Floating Network | Project | +--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------------------+----------------------------------+ | 87295f6b-75ed-4420-9548-a37d4ae137fc | 192.168.122.164 | 10.0.0.5 | 4ca1d30d-9931-495b-a295-5eba2019293f | 2b122467-8cd0-4159-a176-2a4bc4c2f1e7 | 699eeaefb7b84291a75d389ec0f10ea2 | | 8e47ae70-fb99-4a3b-ad66-314b9e1a5400 | 192.168.122.180 | 10.0.0.7 | a8d54ead-3283-4746-94d1-ef724fcd50f9 | 2b122467-8cd0-4159-a176-2a4bc4c2f1e7 | 699eeaefb7b84291a75d389ec0f10ea2 | +--------------------------------------+---------------------+------------------+--------------------------------------+--------------------------&lt;/pre&gt; &lt;p&gt;Looking at the Neutron ports, we can see that, as suspected, those ports are API and Ingress but they are down. So, how can load balancing work? Take a look at this:&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo-static-nic]$ openstack port list | grep "api-port\|ingress" | 4ca1d30d-9931-495b-a295-5eba2019293f | ocp4-4p5fd-api-port | fa:16:3e:5b:2b:eb | ip_address='10.0.0.5', subnet_id='c38b6eb3-0dc3-41ec-915e-e7c365bcb0a0' | DOWN | | a8d54ead-3283-4746-94d1-ef724fcd50f9 | ocp4-4p5fd-ingress-port | fa:16:3e:dc:b7:1b | ip_address='10.0.0.7', subnet_id='c38b6eb3-0dc3-41ec-915e-e7c365bcb0a0' | DOWN |&lt;/pre&gt; &lt;p&gt;Those ports are not attached to an instance. Instead, they are created on the tenant network to be used by OpenShift to allocate VIPs via Keepalived or the Virtual Router Redundancy Protocol (VRRP) in order to load balance the internal services (API and DNS) exposed by masters and the Ingress requests exposed by workers (ingress pod = OpenShift router).&lt;/p&gt; &lt;p&gt;Digging into our OpenShift setup, the project &lt;code&gt;openshift-openstack-infra&lt;/code&gt; contains three &lt;code&gt;haproxy&lt;/code&gt; and three &lt;code&gt;keepalived&lt;/code&gt; pods running on masters plus two &lt;code&gt;keepalived&lt;/code&gt; running on workers:&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo-static-nic]$ oc get pods -n openshift-openstack-infra NAME READY STATUS RESTARTS AGE coredns-ocp4-4p5fd-master-0 1/1 Running 0 9d coredns-ocp4-4p5fd-master-1 1/1 Running 0 9d coredns-ocp4-4p5fd-master-2 1/1 Running 0 9d coredns-ocp4-4p5fd-worker-76gvc 1/1 Running 1 9d coredns-ocp4-4p5fd-worker-n6jvq 1/1 Running 0 9d &lt;strong&gt;haproxy-ocp4-4p5fd-master-0 2/2 Running 2 9d&lt;/strong&gt; &lt;strong&gt;haproxy-ocp4-4p5fd-master-1 2/2 Running 0 9d&lt;/strong&gt; &lt;strong&gt;haproxy-ocp4-4p5fd-master-2 2/2 Running 0 9d&lt;/strong&gt; &lt;strong&gt;keepalived-ocp4-4p5fd-master-0 1/1 Running 0 9d&lt;/strong&gt; &lt;strong&gt;keepalived-ocp4-4p5fd-master-1 1/1 Running 0 9d&lt;/strong&gt; &lt;strong&gt;keepalived-ocp4-4p5fd-master-2 1/1 Running 0 9d&lt;/strong&gt; &lt;strong&gt;keepalived-ocp4-4p5fd-worker-76gvc 1/1 Running 1 9d&lt;/strong&gt; &lt;strong&gt;keepalived-ocp4-4p5fd-worker-n6jvq 1/1 Running 0 9d&lt;/strong&gt; mdns-publisher-ocp4-4p5fd-master-0 1/1 Running 0 9d mdns-publisher-ocp4-4p5fd-master-1 1/1 Running 0 9d mdns-publisher-ocp4-4p5fd-master-2 1/1 Running 0 9d mdns-publisher-ocp4-4p5fd-worker-76gvc 1/1 Running 1 9d mdns-publisher-ocp4-4p5fd-worker-n6jvq 1/1 Running 0 9d&lt;/pre&gt; &lt;p&gt;Looking at one of these pods running on master nodes, we can see that Keepalived was configured to use the VRRP protocol to expose three VIPs:&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo]$ oc rsh keepalived-ocp4-4p5fd-master-0 sh-4.2# cat /etc/keepalived/keepalived.conf | grep -A1 ipaddress virtual_ipaddress { 10.0.0.5/16 -- virtual_ipaddress { 10.0.0.6/16 -- virtual_ipaddress { 10.0.0.7/16&lt;/pre&gt; &lt;p&gt;For instance, in order to route Ingress traffic to internal API ports, there is a VRRP instance with a VIP assigned (10.0.0.5):&lt;/p&gt; &lt;pre&gt;vrrp_instance ocp4_API { state BACKUP interface ens3 virtual_router_id 29 priority 40 advert_int 1 authentication { auth_type PASS auth_pass ocp4_api_vip } virtual_ipaddress { 10.0.0.5/16 } track_script { chk_ocp } }&lt;/pre&gt; &lt;p&gt;Looking at the &lt;code&gt;haproxy&lt;/code&gt; pod on the master, we can see that it listens on port 7443 on all IPs, and that it balances the API calls to the masters&amp;#8217; nodes (section backend masters):&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo]$ oc rsh haproxy-ocp4-4p5fd-master-0 sh-4.2$ cat /etc/haproxy/haproxy.cfg defaults maxconn 20000 mode tcp log /var/run/haproxy/haproxy-log.sock local0 option dontlognull retries 3 timeout http-keep-alive 10s timeout http-request 1m timeout queue 1m timeout connect 10s timeout client 86400s timeout server 86400s timeout tunnel 86400s frontend main bind :7443 default_backend masters listen health_check_http_url bind :50936 mode http monitor-uri /healthz option dontlognull listen stats bind 127.0.0.1:50000 mode http stats enable stats hide-version stats uri /haproxy_stats stats refresh 30s stats auth Username:Password backend masters option httpchk GET /healthz HTTP/1.0 option log-health-checks balance roundrobin server etcd-0.ocp4.osd2019.local. 10.0.0.11:6443 weight 1 verify none check check-ssl inter 3s fall 2 rise 3 server etcd-2.ocp4.osd2019.local. 10.0.0.18:6443 weight 1 verify none check check-ssl inter 3s fall 2 rise 3 server etcd-1.ocp4.osd2019.local. 10.0.0.26:6443 weight 1 verify none check check-ssl inter 3s fall 2 rise 3&lt;/pre&gt; &lt;p&gt;Logging via SSH to the CoresOS node (&lt;code&gt;master-0&lt;/code&gt;) to double-check, we can see that &lt;code&gt;haproxy&lt;/code&gt; is listening on port 7443:&lt;/p&gt; &lt;pre&gt;root@ocp4-4p5fd-master-0 ~]# netstat -anop | grep 0.0.0.0:7443 tcp 0 0 0.0.0.0:7443 0.0.0.0:* LISTEN 336621/haproxy off (0.00/0/0)&lt;/pre&gt; &lt;p&gt;The VIP (10.0.0.5) instead is assigned right now to master-2 node which is the master from a Keepalived perspective:&lt;/p&gt; &lt;pre&gt;root@ocp4-4p5fd-master-1 /]# ip a | grep 10.0.0.5 inet 10.0.0.5/16 scope global secondary ens3&lt;/pre&gt; &lt;p&gt;What is missing? If the API and Ingress port on Neutron are down, how does this setup work? It works because on the Neutron ports assigned to masters and workers, keepalive VIPs are allowed from a port security perspective.&lt;/p&gt; &lt;p&gt;Need to disable anti-MAC spoofing only for particular IPs/MACs? This setting allows incoming traffic from different IPs on the same Neutron port:&lt;/p&gt; &lt;pre&gt;(overcloud) [stack@undercloud osd-ocp-demo-static-nic]$ neutron port-show e3c60257-1877-45c4-8cae-492ef953207f neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +-----------------------+-----------------------------------------------------------------------------------+ | Field | Value | +-----------------------+-----------------------------------------------------------------------------------+ | admin_state_up | True | | allowed_address_pairs | {"ip_address": "10.0.0.5", "mac_address": "fa:16:3e:25:f2:fe"} | | | {"ip_address": "10.0.0.6", "mac_address": "fa:16:3e:25:f2:fe"} | | | {"ip_address": "10.0.0.7", "mac_address": "fa:16:3e:25:f2:fe"} |&lt;/pre&gt; &lt;p&gt;Need to summarize the traffic flow for incoming API traffic? It looks like this:&lt;/p&gt; &lt;pre&gt;192.168.122.164 -&amp;#62; MASTER-2 NODE (holding keepalived VIP) -&amp;#62; master-2 haproxy pod -&amp;#62; load balancing to other pods&lt;/pre&gt; &lt;p&gt;To summarize Ingress traffic flow for incoming HTTP/HTTPS requests:&lt;/p&gt; &lt;pre&gt;192.168.122.180 -&amp;#62; Worker-node (holding keepalived VIP for ingress)  -&amp;#62; console pods, prometheus pods, etc&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; This &lt;a href="https://github.com/openshift/installer/blob/master/docs/design/openstack/networking-infrastructure.md" target="_blank" rel="noopener noreferrer"&gt;page&lt;/a&gt; explains IPI networking infrastructure with a good level of detail.&lt;/p&gt; &lt;p&gt;In addition, I have also tried adding OpenStack Neutron ports to OpenShift nodes and attaching a provider network in order to have a dedicated management network with static IP/routes. Unfortunately, I was not able to accomplish this goal because IPI&amp;#8217;s goal is to provide an opinionated setup. Instead, when User-Provisioned Infrastructure (UPI) is available for Red Hat OpenStack, this addition will give us this option.&lt;/p&gt; &lt;h2&gt;Demo&lt;/h2&gt; &lt;p&gt;Here is the demo video we recorded with my colleague Rinaldo Bergamini. It shows OpenShift IPI installation, in a practical way.&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/GxoWSpQX0Fo?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#38;linkname=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F06%2Fred-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup%2F&amp;#038;title=Red%20Hat%20OpenShift%204.2%20IPI%20on%20OpenStack%2013%3A%20All-in-one%20setup" data-a2a-url="https://developers.redhat.com/blog/2020/02/06/red-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup/" data-a2a-title="Red Hat OpenShift 4.2 IPI on OpenStack 13: All-in-one setup"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/06/red-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup/"&gt;Red Hat OpenShift 4.2 IPI on OpenStack 13: All-in-one setup&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yPfQWPtfzAk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Months ago, a customer asked me about Red Hat OpenShift on OpenStack, especially regarding the network configuration options available in OpenShift at the node level. In order to give them an answer and increase my confidence on $topic, I&amp;#8217;ve considered how to test this scenario. At the same time, the Italian solution architect &amp;#8220;Top Gun [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/06/red-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup/"&gt;Red Hat OpenShift 4.2 IPI on OpenStack 13: All-in-one setup&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">656047</post-id><dc:creator>Michele Naldini</dc:creator><dc:date>2020-02-06T08:00:29Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/06/red-hat-openshift-4-2-ipi-on-openstack-13-all-in-one-setup/</feedburner:origLink></entry><entry><title>Customizing OpenShift project creation</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Vife_RcU9EM/" /><category term="Containers" /><category term="DevOps" /><category term="Modern App Dev" /><category term="customize default project" /><category term="openshift" /><category term="projectRequestTemplate" /><author><name>Rarm Nagalingam</name></author><id>https://developers.redhat.com/blog/?p=673297</id><updated>2020-02-05T08:00:42Z</updated><published>2020-02-05T08:00:42Z</published><content type="html">&lt;p&gt;I recently attended an excellent training run by Red Hat’s Global Partner Enablement Team on advanced &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; management. One of the most interesting elements of the training was how to customize default project creation. This article explains how to use OpenShift&amp;#8217;s &lt;code&gt;projectRequestTemplate&lt;/code&gt; to add default controls for the resources that a project is allowed to consume.&lt;/p&gt; &lt;p&gt;&lt;span id="more-673297"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;First, a little bit of background. OpenShift projects are synonymous with Kubernetes namespaces and are used to isolate objects between projects. By default, users who are authenticated can create projects and consume resources up to the global &lt;code&gt;ClusterResource&lt;/code&gt; limits. As a cluster administrator, you might want to add new default limits around the number of resources that can be consumed by a project. OpenShift provides a mechanism to achieve this setting by creating a template that is referenced by the &lt;code&gt;projectRequestTemplate&lt;/code&gt; parameter in OpenShift’s project configuration resource.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can read more about this feature in the official documentation in &lt;a href="https://docs.openshift.com/container-platform/4.2/applications/projects/configuring-project-creation.html" target="_blank" rel="noopener noreferrer"&gt;configuring-project-creation&lt;/a&gt;. However, the default documentation can be lacking if you haven’t created or modified templates before.&lt;/p&gt; &lt;p&gt;This example outlines how to obtain a project creation template schema, and how to configure it to set default project limits and default container limits. For our example, the project limits for our example look like this:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Use a maximum of 10 pods.&lt;/li&gt; &lt;li&gt;Limit each project to six CPUs.&lt;/li&gt; &lt;li&gt;Limit each project to 16GiB of RAM.&lt;/li&gt; &lt;li&gt;Set a request for a project to four CPUs.&lt;/li&gt; &lt;li&gt;Set a request for a project to 8GiB of RAM.&lt;/li&gt; &lt;li&gt;Set a request for 20GB of persistent storage.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The container limits for our example look like this:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Limit each container to one CPU.&lt;/li&gt; &lt;li&gt;Limit each container to 1GiB of RAM.&lt;/li&gt; &lt;li&gt;Set a default request for 500 milliCPU.&lt;/li&gt; &lt;li&gt;Set a default request for 500MiB of RAM.&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; To understand more about limits and quotas, read &lt;a href="https://docs.openshift.com/container-platform/4.2/applications/quotas/quotas-setting-per-project.html" target="_blank" rel="noopener noreferrer"&gt;quotas-setting-per-project&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Before we can customize the template we need to obtain a schema. Run the following command as a user with &lt;code&gt;cluster-admin&lt;/code&gt; permissions:&lt;/p&gt; &lt;pre&gt;$ oc adm create-bootstrap-project-template -o yaml &amp;#62; template.yaml&lt;/pre&gt; &lt;h2&gt;Customize the template&lt;/h2&gt; &lt;p&gt;Looking at the default template, you can see that it is bare-bones and only contains particular settings, such as &lt;code&gt;NAME&lt;/code&gt;, &lt;code&gt;DISPLAYNAME&lt;/code&gt;, &lt;code&gt;DESCRIPTION&lt;/code&gt;, &lt;code&gt;ADMIN_USER&lt;/code&gt;, and &lt;code&gt;REQUESTING_USER&lt;/code&gt;, along with establishing sane role-based access controls (RBACs):&lt;/p&gt; &lt;pre&gt;apiVersion: template.openshift.io/v1 kind: Template metadata: creationTimestamp: null name: project-request objects: - apiVersion: project.openshift.io/v1 kind: Project metadata: annotations: openshift.io/description: ${PROJECT_DESCRIPTION} openshift.io/display-name: ${PROJECT_DISPLAYNAME} openshift.io/requester: ${PROJECT_REQUESTING_USER} creationTimestamp: null name: ${PROJECT_NAME} spec: {} status: {} - apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: creationTimestamp: null name: admin namespace: ${PROJECT_NAME} roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: admin subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: ${PROJECT_ADMIN_USER} parameters: - name: PROJECT_NAME - name: PROJECT_DISPLAYNAME - name: PROJECT_DESCRIPTION - name: PROJECT_ADMIN_USER - name: PROJECT_REQUESTING_USER &lt;/pre&gt; &lt;p&gt;The important part when customizing this template is adding objects such as &lt;code&gt;ResourceQuota&lt;/code&gt; and &lt;code&gt;LimitRange&lt;/code&gt; under the &lt;code&gt;objects&lt;/code&gt; stanza. First, craft the &lt;code&gt;ResourceQuota&lt;/code&gt; and &lt;code&gt;LimitRange&lt;/code&gt; as you would normally:&lt;/p&gt; &lt;pre&gt;- apiVersion: v1 kind: "LimitRange" metadata: name: project-limits spec: limits: - type: "Container" default: cpu: "1" memory: "1Gi" defaultRequest: cpu: "500m" memory: "500Mi" - apiVersion: v1 kind: ResourceQuota metadata: name: project-quota spec: hard: pods: "10" requests.cpu: "4" requests.memory: 8Gi limits.cpu: "6" limits.memory: 16Gi requests.storage: "20G" &lt;/pre&gt; &lt;p&gt;Now, add &lt;code&gt;ResourceQuota&lt;/code&gt; and &lt;code&gt;LimitRange&lt;/code&gt; objects under the &lt;code&gt;objects&lt;/code&gt; section of the template. In this example, I have modified the name for each object by dynamically include the project name:&lt;/p&gt; &lt;pre&gt;apiVersion: template.openshift.io/v1 kind: Template metadata: creationTimestamp: null name: project-request objects: - apiVersion: project.openshift.io/v1 kind: Project metadata: annotations: openshift.io/description: ${PROJECT_DESCRIPTION} openshift.io/display-name: ${PROJECT_DISPLAYNAME} openshift.io/requester: ${PROJECT_REQUESTING_USER} creationTimestamp: null name: ${PROJECT_NAME} spec: {} status: {} - apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: creationTimestamp: null name: admin namespace: ${PROJECT_NAME} roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: admin subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: ${PROJECT_ADMIN_USER} - apiVersion: v1 kind: "LimitRange" metadata: name: ${PROJECT_NAME}-limits spec: limits: - type: "Container" default: cpu: "1" memory: "1Gi" defaultRequest: cpu: "500m" memory: "500Mi" - apiVersion: v1 kind: ResourceQuota metadata: name: ${PROJECT_NAME}-quota spec: hard: pods: "10" requests.cpu: "4" requests.memory: 8Gi limits.cpu: "6" limits.memory: 16Gi requests.storage: "20G" parameters: - name: PROJECT_NAME - name: PROJECT_DISPLAYNAME - name: PROJECT_DESCRIPTION - name: PROJECT_ADMIN_USER - name: PROJECT_REQUESTING_USER &lt;/pre&gt; &lt;p&gt;The next step is installing the config into the &lt;code&gt;openshift-config&lt;/code&gt; project:&lt;/p&gt; &lt;pre&gt;$ oc create -f template.yaml -n openshift-config&lt;/pre&gt; &lt;p&gt;After this, associate the template with &lt;code&gt;projectRequestTemplate&lt;/code&gt; in the project resource of the &lt;code&gt;config.openshift.io/v1&lt;/code&gt;. Run the following command to edit the config:&lt;/p&gt; &lt;pre&gt;$ oc edit project.config.openshift.io/cluster&lt;/pre&gt; &lt;p&gt;Within the text editor, set the config spec to include the name for your template under &lt;code&gt;projectRequestTemplate&lt;/code&gt;. The name of our template itself was &lt;code&gt;project-request&lt;/code&gt;. Therefore, under the spec section, we would add:&lt;/p&gt; &lt;pre&gt;apiVersion: config.openshift.io/v1 kind: Project metadata: ... spec: projectRequestTemplate: name: project-request &lt;/pre&gt; &lt;h2&gt;&lt;strong&gt;Confirm that the template works&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The last step is to test your configuration. Keep in mind that the project creation template only applies to projects created after the template was installed and associated with the &lt;code&gt;projectRequestTemplate&lt;/code&gt;. Previously created projects will not be modified:&lt;/p&gt; &lt;pre&gt;$ oc new-project test ... $ oc describe project test Name: test Created: 40 seconds ago ... Quota: Name: test-quota Resource Used Hard -------- ---- ---- limits.cpu 0 6 limits.memory 0 16Gi pods 0 10 requests.cpu 0 4 requests.memory 0 8Gi requests.storage 0 20G Resource limits: Name: test-limits Type Resource Min Max Default Request Default Limit Max Limit/Request Ratio ---- -------- --- --- --------------- ------------- ----------------------- Container cpu - - 500m 1 - Container memory - - 500Mi 1Gi - &lt;/pre&gt; &lt;p&gt;The output above confirms that the quota and resource limits have automatically been applied to the project.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#38;linkname=Customizing%20OpenShift%20project%20creation" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F05%2Fcustomizing-openshift-project-creation%2F&amp;#038;title=Customizing%20OpenShift%20project%20creation" data-a2a-url="https://developers.redhat.com/blog/2020/02/05/customizing-openshift-project-creation/" data-a2a-title="Customizing OpenShift project creation"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/05/customizing-openshift-project-creation/"&gt;Customizing OpenShift project creation&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Vife_RcU9EM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;I recently attended an excellent training run by Red Hat’s Global Partner Enablement Team on advanced Red Hat OpenShift management. One of the most interesting elements of the training was how to customize default project creation. This article explains how to use OpenShift&amp;#8217;s projectRequestTemplate to add default controls for the resources that a project is [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/05/customizing-openshift-project-creation/"&gt;Customizing OpenShift project creation&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">673297</post-id><dc:creator>Rarm Nagalingam</dc:creator><dc:date>2020-02-05T08:00:42Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/05/customizing-openshift-project-creation/</feedburner:origLink></entry><entry><title>How to use third-party APIs in Operator SDK projects</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/s8zFuWXf0e4/" /><category term="DevOps" /><category term="Kubernetes" /><category term="Operator" /><category term="APIs" /><category term="Golang" /><category term="openshift" /><category term="operator framework" /><category term="operator-sdk" /><author><name>Camila Macedo</name></author><id>https://developers.redhat.com/blog/?p=672447</id><updated>2020-02-04T08:00:18Z</updated><published>2020-02-04T08:00:18Z</published><content type="html">&lt;p&gt;The &lt;a href="https://coreos.com/blog/introducing-operator-framework" target="_blank" rel="noopener noreferrer"&gt;Operator Framework&lt;/a&gt; is an open source toolkit for managing Kubernetes-native applications. This framework and its features provide the ability to develop tools that simplify complexities, such as installing, configuring, managing, and packaging applications on &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;. In this article, we show how to use third-party APIs in &lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;Operator-SDK&lt;/a&gt; projects.&lt;/p&gt; &lt;p&gt;In projects built with Operator-SDK, only the Kubernetes API schemas are added by default. However, you might need to create, read, update, or delete a resource that is from another API—even one that you created yourself via other Operator projects.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s check out an example scenario: How to create a &lt;a href="https://docs.openshift.com/container-platform/4.2/networking/routes/route-configuration.html" target="_blank" rel="noopener noreferrer"&gt;Route&lt;/a&gt; resource from the OpenShift API for an Operator-SDK project.&lt;/p&gt; &lt;p&gt;&lt;span id="more-672447"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Step 1: Get the API module&lt;/h2&gt; &lt;p&gt;In your project&amp;#8217;s directory, run the following command via the command line to get the OpenShift API module:&lt;/p&gt; &lt;pre class="part" data-endline="15" data-startline="13"&gt;$ go get -u github.com/openshift/api&lt;/pre&gt; &lt;h2&gt;Step 2: Use the Discovery API to see if the new API is present&lt;/h2&gt; &lt;p&gt;The best approach at this point is to make sure that the resource is available in the cluster because we are using a third-party API. You can learn how to check that the resource is available by reading &lt;a href="https://developers.redhat.com/blog/2020/01/22/why-not-couple-an-operators-logic-to-a-specific-kubernetes-platform/"&gt;&lt;em&gt;Why not couple an Operator&amp;#8217;s logic to a specific Kubernetes platform?&lt;/em&gt;&lt;/a&gt;&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If what you are building must run on a specific Kubernetes platform (for example, OpenShift) be aware that users might still try to use your project with other Kubernetes platform vendors. For example, they might try to check your Operator with Minikube. In this scenario, your project might fail if you do not adequately implement it because the OpenShift APIs will not be present. Best practices recommend that you create Operator projects that are supportable for both scenarios. In this example, we could use the &lt;a href="https://docs.okd.io/latest/rest_api/apis-route.openshift.io/v1.Route.html" target="_blank" rel="noopener noreferrer"&gt;v1.Route&lt;/a&gt; if it is available in the cluster, or we could create an &lt;a href="https://kubernetes.io/docs/concepts/services-networking/ingress" target="_blank" rel="noopener noreferrer"&gt;Ingress&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Step 3: Register the API with the scheme&lt;/h2&gt; &lt;p&gt;In the &lt;code&gt;main.go&lt;/code&gt; file, add the schema before the line &lt;code&gt;Setup all Controllers&lt;/code&gt;:&lt;/p&gt; &lt;pre class="part" data-endline="46" data-startline="31"&gt; ... // Adding the routev1 if err := routev1.AddToScheme(mgr.GetScheme()); err != nil { log.Error(err, "") os.Exit(1) } // Setup all Controllers if err := controller.AddToManager(mgr); err != nil { log.Error(err, "") os.Exit(1) } ... &lt;/pre&gt; &lt;p&gt;Note that you need to import the module as well:&lt;/p&gt; &lt;pre class="part" data-endline="56" data-startline="50"&gt;import ( ... routev1 "github.com/openshift/api/route/v1" ... )&lt;/pre&gt; &lt;h2&gt;Step 4: Use the API in the controllers&lt;/h2&gt; &lt;p&gt;Now, we can create the &lt;a href="https://docs.openshift.com/container-platform/4.3/networking/routes/route-configuration.html" target="_blank" rel="noopener noreferrer"&gt;Route&lt;/a&gt; resource in the &lt;code&gt;controller.go&lt;/code&gt; file&amp;#8217;s &lt;code&gt;Reconcile&lt;/code&gt; function. Continuing with our example:&lt;/p&gt; &lt;pre class="part" data-endline="81" data-startline="62"&gt; ... route := &amp;#38;routev1.Route{} err = r.client.Get(context.TODO(), types.NamespacedName{Name: memcached.Name, Namespace: memcached.Namespace}, route) if err != nil &amp;#38;&amp;#38; errors.IsNotFound(err) { // Define a new Rooute object route = r.routeForMemcached(memcached) reqLogger.Info("Creating a new Route.", "Route.Namespace", route.Namespace, "Route.Name", route.Name) err = r.client.Create(context.TODO(), route) if err != nil { reqLogger.Error(err, "Failed to create new Route.", "Route.Namespace", route.Namespace, "Route.Name", route.Name) return reconcile.Result{}, err } } else if err != nil { reqLogger.Error(err, "Failed to get Route.") return reconcile.Result{}, err } ...&lt;/pre&gt; &lt;p&gt;Create the Route itself:&lt;/p&gt; &lt;pre class="part" data-endline="113" data-startline="83"&gt;// routeForMemcached returns the route resource func (r *ReconcileMemcached) routeForMemcached(m *cachev1alpha1.Memcached) *routev1.Route { ls := labelsForMemcached(m.Name) route := &amp;#38;routev1.Route{ ObjectMeta: metav1.ObjectMeta{ Name: m.Name, Namespace: m.Namespace, Labels: ls, }, Spec: routev1.RouteSpec{ To: routev1.RouteTargetReference{ Kind: "Service", Name: m.Name, }, Port: &amp;#38;routev1.RoutePort{ TargetPort: intstr.FromString(m.Name), }, TLS: &amp;#38;routev1.TLSConfig{ Termination: routev1.TLSTerminationEdge, }, }, } // Set MobileSecurityService mss as the owner and controller controllerutil.SetControllerReference(m, route, r.scheme) return route }&lt;/pre&gt; &lt;p&gt;Also, it is possible to re-trigger the reconcile if any change occurs on this resource:&lt;/p&gt; &lt;pre class="part" data-endline="126" data-startline="117"&gt; err = c.Watch(&amp;#38;source.Kind{Type: &amp;#38;routev1.Route{}}, &amp;#38;handler.EnqueueRequestForOwner{ IsController: true, OwnerType: &amp;#38;cachev1alpha1.Memcached{}, }) if err != nil { return err } &lt;/pre&gt; &lt;h2&gt;Step 5: Use the API to implement unit tests&lt;/h2&gt; &lt;p&gt;You need to develop tests to check your implementation in order to add the third-party schema into the manager used by the &lt;a href="https://godoc.org/sigs.k8s.io/controller-runtime/pkg/client/fake" target="_blank" rel="noopener noreferrer"&gt;fake client&lt;/a&gt; provided by the &lt;a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener noreferrer"&gt;Operator-SDK&lt;/a&gt; test framework. See the following example:&lt;/p&gt; &lt;pre class="part" data-endline="149" data-startline="132"&gt;func buildReconcileWithFakeClient(objs []runtime.Object, t *testing.T) *ReconcileMemcached { s := scheme.Scheme // Add route Openshift scheme if err := routev1.AddToScheme(s); err != nil { t.Fatalf("Unable to add route scheme: (%v)", err) } s.AddKnownTypes(&amp;#38;v1alpha1.Memcached{}, &amp;#38;v1alpha1.AppService{}) // create a fake client to mock API calls with the mock objects cl := fake.NewFakeClient(objs...) // create a ReconcileMemcached object with the scheme and fake client return &amp;#38;ReconcileMemcached{client: cl, scheme: s} }&lt;/pre&gt; &lt;p&gt;Use the above function to implement the tests as follows:&lt;/p&gt; &lt;pre class="part" data-endline="187" data-startline="154"&gt;func TestReconcileMemcached(t *testing.T) { type fields struct { scheme *runtime.Scheme } type args struct { instance *1alpha1.Memcached kind string } tests := []struct { name string fields fields args args want reconcile.Result wantErr bool wantPanic bool }{ // TODO: Tests } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { objs := []runtime.Object{tt.args.instance} r := buildReconcileWithFakeClient(objs, t) if (err != nil) != tt.wantErr { t.Errorf("TestReconcileMemcached error = %v, wantErr %v", err, tt.wantErr) return } }) } }&lt;/pre&gt; &lt;p&gt;Now, you know how to use third-party APIs in your Operator projects. And not just that, you also have a good idea about the code&amp;#8217;s re-use capabilities as well.&lt;/p&gt; &lt;p&gt;I&amp;#8217;d like to thank @Joe Lanford, who also collaborated with feedback and input for this article.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#38;linkname=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F04%2Fhow-to-use-third-party-apis-in-operator-sdk-projects%2F&amp;#038;title=How%20to%20use%20third-party%20APIs%20in%20Operator%20SDK%20projects" data-a2a-url="https://developers.redhat.com/blog/2020/02/04/how-to-use-third-party-apis-in-operator-sdk-projects/" data-a2a-title="How to use third-party APIs in Operator SDK projects"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/04/how-to-use-third-party-apis-in-operator-sdk-projects/"&gt;How to use third-party APIs in Operator SDK projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/s8zFuWXf0e4" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Operator Framework is an open source toolkit for managing Kubernetes-native applications. This framework and its features provide the ability to develop tools that simplify complexities, such as installing, configuring, managing, and packaging applications on Kubernetes and Red Hat OpenShift. In this article, we show how to use third-party APIs in Operator-SDK projects. In projects [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/04/how-to-use-third-party-apis-in-operator-sdk-projects/"&gt;How to use third-party APIs in Operator SDK projects&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">672447</post-id><dc:creator>Camila Macedo</dc:creator><dc:date>2020-02-04T08:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/04/how-to-use-third-party-apis-in-operator-sdk-projects/</feedburner:origLink></entry><entry><title>KIE Decision Tooling blog</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rWkSysT6SSk/kie-decision-tooling-blog.html" /><category term="feed_group_name_drools" scheme="searchisko:content:tags" /><category term="feed_name_drools" scheme="searchisko:content:tags" /><author><name>Unknown</name></author><id>searchisko:content:id:jbossorg_blog-kie_decision_tooling_blog</id><updated>2020-02-03T23:34:58Z</updated><published>2020-02-03T23:34:00Z</published><content type="html">&lt;p&gt;KIE Decision Tooling is the team responsible for building web editors to support business decisions, and now it has a blog. &lt;/p&gt;&lt;p&gt;We're still cross-posting feature releases here. But, you can also find specific content regarding the technologies that orbit the web tooling there. &lt;/p&gt;&lt;p&gt;In our first post, we're presenting the new code completion feature in the DMN editor, check it out: &lt;a href="https://medium.com/kie-decision-tooling/feel-functions-and-the-dmn-editor-7f4462f9f012"&gt;https://medium.com/kie-decision-tooling/feel-functions-and-the-dmn-editor-7f4462f9f012&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Follow the RSS here: &lt;a href="https://medium.com/feed/kie-decision-tooling"&gt;https://medium.com/feed/kie-decision-tooling&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Stay tuned for the next posts! :-) &lt;/p&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=tHuuT0pvSJs:L_57tfrrEdw:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:dnMXMwOfBR0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=dnMXMwOfBR0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=tHuuT0pvSJs:L_57tfrrEdw:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=tHuuT0pvSJs:L_57tfrrEdw:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=tHuuT0pvSJs:L_57tfrrEdw:jWeZv7XsJd0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=jWeZv7XsJd0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/DroolsAtom/~4/tHuuT0pvSJs" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rWkSysT6SSk" height="1" width="1" alt=""/&gt;</content><summary>KIE Decision Tooling is the team responsible for building web editors to support business decisions, and now it has a blog. We're still cross-posting feature releases here. But, you can also find specific content regarding the technologies that orbit the web tooling there. In our first post, we're presenting the new code completion feature in the DMN editor, check it out: https://medium.com/kie-de...</summary><dc:creator>Unknown</dc:creator><dc:date>2020-02-03T23:34:00Z</dc:date><feedburner:origLink>http://feeds.athico.com/~r/DroolsAtom/~3/tHuuT0pvSJs/kie-decision-tooling-blog.html</feedburner:origLink></entry><entry><title>Camel K standalone Java file: Now with Java language support</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5qL2oSxJytc/" /><category term="Developer Tools" /><category term="Java" /><category term="Modern App Dev" /><category term="Camel K" /><category term="Fuse Tooling" /><category term="Red Hat Integration" /><category term="Visual Studio Code" /><author><name>Aurélien Pupier</name></author><id>https://developers.redhat.com/blog/?p=671807</id><updated>2020-02-03T08:00:43Z</updated><published>2020-02-03T08:00:43Z</published><content type="html">&lt;p&gt;&lt;a href="https://camel.apache.org/projects/camel-k/" target="_blank" rel="noopener noreferrer"&gt;Apache Camel K&lt;/a&gt; should be as lightweight as possible. Therefore, the Camel K project provides standalone Java files to describe a Camel integration. The downside to this practice is that existing IDEs cannot provide complete support out of the box. To provide a complete experience with Apache Camel K&amp;#8217;s standalone Java files, there were three solutions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create a fake project with Camel dependencies.&lt;/li&gt; &lt;li&gt;Add all jar dependencies manually in a lib folder at the root of the workspace.&lt;/li&gt; &lt;li&gt;Use the newest &lt;a href="https://github.com/redhat-developer/vscode-java/pull/1196"&gt;&lt;code&gt;java.project.referencedLibraries&lt;/code&gt; preference&lt;/a&gt; from Red Hat&amp;#8217;s &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.java"&gt;Language Support for Java&lt;/a&gt; extension.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;As a result, there is no intuitive configuration. However, Red Hat&amp;#8217;s &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-camelk" target="_blank" rel="noopener noreferrer"&gt;Tooling for Apache Camel K&lt;/a&gt; offers a new possibility.&lt;/p&gt; &lt;p&gt;&lt;span id="more-671807"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;With Tooling for Apache Camel K version 0.11.0, Java language support is now included, and there are only two requirements. First, you need to have the word &amp;#8220;camel&amp;#8221; in the Java file&amp;#8217;s content. Most of the time, this requirement is satisfied by the import package, itself. Second, you must have no project in the workspace. If there &lt;em&gt;are&lt;/em&gt; projects, we expect that the classic Maven/Gradle build provides the Java language support. However, these requirements should not be a problem in most cases.&lt;/p&gt; &lt;p&gt;Here is the completion process on an Apache Camel K standalone Java file:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-680497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/02/ezgif.com-resize.gif" src="https://developers.redhat.com/blog/wp-content/uploads/2020/02/ezgif.com-resize.gif" alt="Java Completion on Standalone Camel K files" width="640" height="355" /&gt;&lt;/p&gt; &lt;p&gt;Next, you might try to transpose the tutorial &lt;em&gt;&lt;a href="https://developers.redhat.com/blog/2019/09/30/sending-a-telegram-with-apache-camel-k-and-visual-studio-code/"&gt;Sending a telegram with Apache Camel K and Visual Studio Code&lt;/a&gt;&lt;/em&gt; using Java.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#38;linkname=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F02%2F03%2Fcamel-k-standalone-java-file-now-with-java-language-support%2F&amp;#038;title=Camel%20K%20standalone%20Java%20file%3A%20Now%20with%20Java%20language%20support" data-a2a-url="https://developers.redhat.com/blog/2020/02/03/camel-k-standalone-java-file-now-with-java-language-support/" data-a2a-title="Camel K standalone Java file: Now with Java language support"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/03/camel-k-standalone-java-file-now-with-java-language-support/"&gt;Camel K standalone Java file: Now with Java language support&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5qL2oSxJytc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Apache Camel K should be as lightweight as possible. Therefore, the Camel K project provides standalone Java files to describe a Camel integration. The downside to this practice is that existing IDEs cannot provide complete support out of the box. To provide a complete experience with Apache Camel K&amp;#8217;s standalone Java files, there were three [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/02/03/camel-k-standalone-java-file-now-with-java-language-support/"&gt;Camel K standalone Java file: Now with Java language support&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">671807</post-id><dc:creator>Aurélien Pupier</dc:creator><dc:date>2020-02-03T08:00:43Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/02/03/camel-k-standalone-java-file-now-with-java-language-support/</feedburner:origLink></entry><entry><title>Click-through learning with VS Code and Didact</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ICVIL6nh3Ik/" /><category term="Developer Tools" /><category term="UI/UX" /><category term="VS Code" /><category term="Didact" /><category term="help framework" /><category term="tutorial" /><category term="VS Code Extensions" /><author><name>Brian Fitzpatrick</name></author><id>https://developers.redhat.com/blog/?p=672137</id><updated>2020-01-31T08:00:36Z</updated><published>2020-01-31T08:00:36Z</published><content type="html">&lt;p&gt;The Didact project is designed to fill a void in Visual Studio Code, but what exactly is it? And more importantly, why should you care?&lt;/p&gt; &lt;p&gt;Didact started as a &amp;#8220;What if?&amp;#8221; VS Code doesn’t provide a great way to walk users through a step-wise tutorial. &amp;#8220;What if&amp;#8221; we could meet that need by combining the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A simple markup language (such as Markdown or AsciiDoc).&lt;/li&gt; &lt;li&gt;The ability to render the markup as HTML using the VS Code webview.&lt;/li&gt; &lt;li&gt;A way to invoke the commands we create for each VS Code extension.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;And over the course of a day or so of coding, I had a working prototype.&lt;/p&gt; &lt;p&gt;&lt;span id="more-672137"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Why Didact?&lt;/h2&gt; &lt;p&gt;We needed a name, so after Googling for unique words I didn’t find in the VS Code Marketplace, I came across &amp;#8220;Didact.&amp;#8221; A Didact is an individual gifted, trained, or intending to instruct—a perfect term to describe what we’re after.&lt;/p&gt; &lt;p&gt;At a high level, the Didact framework is meant to instruct users in a useful way regarding how to complete tasks. The project does this through a combination of text, images, and active links that show VS Code functionality in action. The tricky part is that Didact should make it easy for non-developers to not only write the tutorials but also to interact with the commands they want to invoke. That’s where markup languages like Markdown and AsiiDoc come into the picture. The power comes from pairing that simplicity with VS Code&amp;#8217;s simple command framework.&lt;/p&gt; &lt;h2&gt;So what does Didact do?&lt;/h2&gt; &lt;p&gt;When developers write a VS Code extension, they create commands and call them via menus, buttons, and the command palette. The API provides a great way to invoke them in other places, too. That’s what we leverage Didact.&lt;/p&gt; &lt;p&gt;The goal of Didact is to employ the &amp;#8220;Tell Them, Tell Them Again, and then Tell Them What You Told Them&amp;#8221; approach using a combination of text (or text and images) and actions. Imagine that you are presented with Figure 1 in VS Code.&lt;/p&gt; &lt;div id="attachment_672167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672167" class="wp-image-672167 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example-1024x576.png" alt="Didact window showing a simple demonstration of how to bring up the Command Palette" width="640" height="360" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example-1024x576.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example-768x432.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672167" class="wp-caption-text"&gt;Figure 1: Get help by using VS Code to open a Didact window.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This window offers a couple of things. At the top, it provides a brief description that explains what the Command Palette is used for and how to access it. Below, it includes a simple link that opens the palette with a click, showing what happens when you press the right series of keys (e.g., Ctrl+Shift+P).&lt;/p&gt; &lt;p&gt;If you click the link, it shows you how to invoke a command through the regular keys or menu items, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_672177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672177" class="wp-image-672177 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example2-1024x576.png" alt="Clicking on the &amp;#34;click here&amp;#34; link opens the Command Palette as though you pressed the key combination or accessed it via the menu." width="640" height="360" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example2-1024x576.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example2-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/didact-view-command-palette-example2-768x432.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672177" class="wp-caption-text"&gt;Figure 2: Click the link to show how to reach a command in the palette.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The text itself is written in Markdown and pulls in simple images plus a few links. All the &amp;#8220;heavy lifting&amp;#8221; behind the scenes in the active Didact link is provided through a simple URI:&lt;/p&gt; &lt;pre&gt;didact://?commandId=workbench.action.showCommands&amp;#38;completion=Opened%20Command%20Palette.&lt;/pre&gt; &lt;p&gt;If we unpack that URI, we find the command ID for &lt;code&gt;showCommands&lt;/code&gt; in VS Code (which is triggered when you press Ctrl+Shift+P on your keyboard) and a completion message that shows what Didact did behind the scenes in a small information popup in the lower right corner, as shown in Figure 2.&lt;/p&gt; &lt;p&gt;So, in this case, we told you what we were going to tell you, told you, showed it in action, and then showed it again, reinforcing the effects of clicking the right keys.&lt;/p&gt; &lt;h2&gt;What’s next for Didact?&lt;/h2&gt; &lt;p&gt;We’re just getting started with Didact and have plans to expand in a variety of ways, including the project scaffolding functionality. Scaffolding lets you quickly create a folder/file structure with example files to get you started with the amazing technologies VS Code lets you access.&lt;/p&gt; &lt;p&gt;If you’re interested in checking out this evolving framework, or want to get involved, we encourage you to drop by our &lt;a href="https://github.com/redhat-developer/vscode-didact" target="_blank" rel="noopener noreferrer"&gt;GitHub project page&lt;/a&gt; and poke around. Or, &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-didact" target="_blank" rel="noopener noreferrer"&gt;install the &lt;code&gt;vscode-didact&lt;/code&gt; extension&lt;/a&gt; and play with it locally.&lt;/p&gt; &lt;p&gt;It’s early, but we’re excited to see where Didact evolves over the next few months. Have ideas for how this framework can be used? We’d love to hear from you!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#38;linkname=Click-through%20learning%20with%20VS%20Code%20and%20Didact" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F31%2Fclick-through-learning-with-vs-code-and-didact%2F&amp;#038;title=Click-through%20learning%20with%20VS%20Code%20and%20Didact" data-a2a-url="https://developers.redhat.com/blog/2020/01/31/click-through-learning-with-vs-code-and-didact/" data-a2a-title="Click-through learning with VS Code and Didact"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/31/click-through-learning-with-vs-code-and-didact/"&gt;Click-through learning with VS Code and Didact&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ICVIL6nh3Ik" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Didact project is designed to fill a void in Visual Studio Code, but what exactly is it? And more importantly, why should you care? Didact started as a &amp;#8220;What if?&amp;#8221; VS Code doesn’t provide a great way to walk users through a step-wise tutorial. &amp;#8220;What if&amp;#8221; we could meet that need by combining the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/31/click-through-learning-with-vs-code-and-didact/"&gt;Click-through learning with VS Code and Didact&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">672137</post-id><dc:creator>Brian Fitzpatrick</dc:creator><dc:date>2020-01-31T08:00:36Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/31/click-through-learning-with-vs-code-and-didact/</feedburner:origLink></entry><entry><title>Apache Camel 3.1 - More camel-core optimizations coming (Part 2)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Phl5pSWZdzw/apache-camel-31-more-camel-core_30.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="roadmap" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-apache_camel_3_1_more_camel_core_optimizations_coming_part_2</id><updated>2020-01-30T11:34:14Z</updated><published>2020-01-30T11:34:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I have previously &lt;a href="http://www.davsclaus.com/2020/01/apache-camel-31-more-camel-core.html"&gt;blogged about the optimizations we are doing in the next Camel 3.1 release (part 1)&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Today I wanted to post a status update on the progress we have made since, about 4 weeks later.&lt;br /&gt;&lt;br /&gt;We have focused on optimizing camel-core in three areas:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;unnecessary object allocations&lt;/li&gt;&lt;li&gt;unnecessary method calls&lt;/li&gt;&lt;li&gt;improve performance&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;In other words we are making Camel create less objects, calling fewer methods, and improving the performance during routing.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;To help identify these issues in camel-core we were using a simple Camel route:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;from timer:foo&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to log:foo&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;And other times we focused on longer routes:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;from timer:foo&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to log:foo1&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to log:foo2&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to log:foo3&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; ...&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to log:fooN&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;Or the focus on the bean component:&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;from timer:foo&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&amp;nbsp; to bean:foo&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;And so on. We also added an option to the timer component to not include metadata so the message dont contain any body, headers or exchange properties. This allowed us to focus on the pure routing engine and its overhead.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;So all together this has helped identify many smaller points for improvements that collectively gains a great win.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;b&gt;tl:dr - Show me the numbers&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Okay let's post some numbers first and then follow up with details what has been done.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;u&gt;&lt;b&gt;Object Allocations - (5 minute sampling)&lt;/b&gt;&lt;/u&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;2.9 M objects created&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;55 M objects created&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; 1.8 M objects created&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Okay we have to admit that Camel 3.0 has an issue with excessive object allocations during routing. There are no memory leaks but it creates a lot of unnecessary objects. And I will get into details below why.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;However what is interesting is the gain between Camel 2.25 and 3.1 (40% less objects created).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;u&gt;&lt;b&gt;Method Calls - (5 minute sampling)&lt;/b&gt;&lt;/u&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;139 different Camel methods in use&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; 167 different Camel methods in use&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;84 different Camel methods in use&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;The table above lists the number of methods from Camel that Camel calls during routing. The data does not include all the methods from the JDK. As we cannot optimize those, but we can optimize the Camel source code.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;As you can see from the table we have improvement. Camel 3.1 uses less than half of 3.0, and 40% less than Camel 2.2.5.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;b&gt;Camel 3.0&lt;/b&gt;&lt;/div&gt;&lt;div&gt;Okay so Camel 3.0 has a problem with using too much memory. A big reason is the new reactive executor which now executes each step in the routing via event looping, by handing over tasks to a queue and having workers that execute the tasks. So this handoff now requires creating additional objects and storing tasks in queue etc.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Some of the biggest wins was to avoid creating TRACE logging message which unfortunately was always created regardless if TRACE logging level was enabled. Another big win was to avoid creating toString representation of the route processes with child elements. Instead Camel now only output the id of the process which is a fast operation and dont allocate new objects.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Another problem was new code that are using java.util.stream. This is both a blessing and a curse (mostly a curse for fast code). So by using plain for loops, if structures, and avoiding java.util.stream in the critical parts of core routing engine we reduces object allocations.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Camel 3 is also highly modularised, and for example in Camel 2.x we had all classes in the same classpath and could use instanceof checks. So in Camel 3 we had some code that performed poorly doing these kind of checks (java util streams again).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Another problem was the reactive executor which was using a LinkedList as its queue. So if you have tasks going into the queue and workers processing them in the same pace, so the queue is empty/drained, then LinkedList performs poorly as it allocates/deallocates the object constantly. By switching to a ArrayQueue which has a pre-allocated size of 16 then there is always room in the queue for tasks and no allocation/deallocation happens.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;There are many more optimisations but those mentioned above where likely the biggest problems. Then a lot of smaller optimisations gained a lot combined.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Many smaller&amp;nbsp;optimisations&lt;/b&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The UUID generator of Camel is using a bit of string concat which costs. We have reduced the need for generating UUIDs in the message and unit of work so we only generate 1 per exchange.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The internal advices in the Camel routing engine (advice = before/after AOP). Some of these advices has state which they need to carry over from before to after, which means an object needs to be stored. Before we allocated an array for all advices even for those whom do not have state and thus storing a null. Now we only allocate the array with the exact number of advices that has state. (very small win, eg object[6] vs object[2] etc, but this happens per step in the Camel route, so it all adds up.). Another win was to avoid doing an AOP around UnitOfWork if it was not necessary from the internal routing processor. This avoids additional method calls and to allocate a callback object for the after task. As all of this happens for each step in the routing then its a good improvement.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Some of the most used EIPs has been optimized. For example &lt;to&gt; allows you to send the message to an endpoint using a different MEP (but this is rarely used). Now the EIP detects this and avoids creating a callback object for restoring the MEP. The pipeline EIP (eg when you do to -&amp;gt; to -&amp;gt; to) also has a little improvement to use an index counter instead of java.util.Iterator, as the latter allocates an extra object&lt;/to&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Camel also has a StopWatch that used a java.util.Date to store the time. This was optimized to use a long value.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Another improvement is the event notification. We now pre-calculate if its in use and avoid calling it all together for events related to routing messages. BTW in Camel 3.0 the event notifier was refactored to use Java 8 Supplier's and many fancy APIs but all of that created a lot of overhead. In Camel 3.1 we have restored the notifier to be like before in Camel 2.x and with additional optimisations.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;So let me end this blog by saying that .... awesome. Camel 3.1 will use less memory, execute faster by not calling as many methods (mind that we may have had to move some code which was required to be called but doing this in a different way to avoid calling too many methods).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;One of the bigger changes in terms of touched source code was to switch from using an instance based logger in ServiceSupport (base class for many things in Camel), to use a static logger instance. This means that there will be less Logger objects created and it's also better practice.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Better performance&lt;/b&gt;&lt;/div&gt;&lt;div&gt;Other improvements is that we have moved some of the internal state that Camel kept as exchange properties to fields on the Exchange directly. This avoids storing a key/value in the properties map, but we can use primitives like boolean, int etc. This also performs better as its faster to get a boolean via a getter than to lookup the value in a Map via a key.&amp;nbsp;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;In fact in Camel 3.1 then during regular routing then Camel doesnt lookup any such state from exchange properties which means there is no method calls. There are still some state that are stored as exchange properties (some of those may be improved in the future, however most of these states are only used infrequently). What we have optimized is the state that are always checked and used during routing.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;u&gt;&lt;b&gt;Exchange getProperty(5 minute sampling)&lt;/b&gt;&lt;/u&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;572598&amp;nbsp; &amp;nbsp;getPropety(String)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;161502&amp;nbsp; &amp;nbsp;getPropety(String, Object)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;161502&amp;nbsp; &amp;nbsp;getPropety(String, Object, Class)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 2.25&amp;nbsp; &amp;nbsp; &amp;nbsp;141962&amp;nbsp; &amp;nbsp;getPropeties()&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; 574944&amp;nbsp; &amp;nbsp;getProperty(String)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; 167904&amp;nbsp; &amp;nbsp;getPropety(String, Object)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; 167904&amp;nbsp; &amp;nbsp;getPropety(String, Object, Class)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.0&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;91584&amp;nbsp; &amp;nbsp;getPropeties()&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0&amp;nbsp; &amp;nbsp;getProperty(String)&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0&amp;nbsp; &amp;nbsp;getPropety(String, Object)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0&amp;nbsp; &amp;nbsp;getPropety(String, Object, Class)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style="font-family: Courier New, Courier, monospace;"&gt;Camel 3.1&amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp; &amp;nbsp;0&amp;nbsp; &amp;nbsp;getPropeties()&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;As you can see Camel 2.25 and 3.0 lookup this state a lot. And in Camel 3.1 we have optimized this tremendously and there are no lookup at all - as said the state is stored on the Exchange as primitive types which the JDK can inline and execute really fast.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;The screenshot below shows Camel 2.25 vs 3.1. (The screenshot for 3.1 is slightly outdated as it was from yesterday and we have optimised Camel since). See screenshot below:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0WVTF5BHjBU/XjK-kB9iHCI/AAAAAAAACEQ/Ks4WHFp8KWghMqn2lOHue44pYDOFuy-DgCLcBGAsYHQ/s1600/count-225vs310.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="357" data-original-width="1044" height="217" src="https://1.bp.blogspot.com/-0WVTF5BHjBU/XjK-kB9iHCI/AAAAAAAACEQ/Ks4WHFp8KWghMqn2lOHue44pYDOFuy-DgCLcBGAsYHQ/s640/count-225vs310.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Okay there are many other smaller optimizations and I am working on one currently as I write this blog. Okay let me end this blog, and save details for part 3.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=f88C4KV1Q2k:BBf-Loy3dog:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=f88C4KV1Q2k:BBf-Loy3dog:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=f88C4KV1Q2k:BBf-Loy3dog:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=f88C4KV1Q2k:BBf-Loy3dog:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=f88C4KV1Q2k:BBf-Loy3dog:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=f88C4KV1Q2k:BBf-Loy3dog:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=f88C4KV1Q2k:BBf-Loy3dog:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/f88C4KV1Q2k" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Phl5pSWZdzw" height="1" width="1" alt=""/&gt;</content><summary>I have previously blogged about the optimizations we are doing in the next Camel 3.1 release (part 1). Today I wanted to post a status update on the progress we have made since, about 4 weeks later. We have focused on optimizing camel-core in three areas: unnecessary object allocations unnecessary method calls improve performance In other words we are making Camel create less objects, calling fewe...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2020-01-30T11:34:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/f88C4KV1Q2k/apache-camel-31-more-camel-core_30.html</feedburner:origLink></entry><entry><title>Vault IDs in Red Hat Ansible and Red Hat Ansible Tower</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FVKU_9xYZ-8/" /><category term="CI/CD" /><category term="DevOps" /><category term="Security" /><category term="Ansible" /><category term="Ansible Tower" /><category term="playbook encryption" /><category term="vault ID" /><author><name>Sreejith Anujan</name></author><id>https://developers.redhat.com/blog/?p=667017</id><updated>2020-01-30T08:00:10Z</updated><published>2020-01-30T08:00:10Z</published><content type="html">&lt;p&gt;This article demonstrates the use of multiple vault passwords through vault IDs. You will learn how to use vault IDs to encrypt a file and a string. Once they&amp;#8217;re encrypted, the vault ID can be referenced inside a playbook and used within &lt;a href="https://www.ansible.com/" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ansible&lt;/a&gt; and &lt;a href="https://www.ansible.com/products/tower" target="_blank" rel="noopener noreferrer"&gt;Red Hat Ansible Tower&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Starting with Ansible 2.4 and above, vault IDs are supported&lt;/h2&gt; &lt;p&gt;Vault IDs help you encrypt different files with different passwords to be referenced inside a playbook. Before Ansible 2.4, only one vault password could be used in each Ansible playbook. In effect, every file needed to be encrypted using the same vault password.&lt;/p&gt; &lt;p&gt;To begin with, vault IDs need to be pre-created and referenced inside your &lt;code&gt;ansible.cfg&lt;/code&gt; file. The following excerpt is from &lt;code&gt;ansible-config list&lt;/code&gt; for the configuration &lt;code&gt;DEFAULT_VAULT_IDENTITY_LIST&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;&lt;span id="more-667017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;default: [] description: A list of vault-ids to use by default. Equivalent to multiple --vault-id args. Vault-ids are tried in order. env: - {name: ANSIBLE_VAULT_IDENTITY_LIST} ini: - {key: vault_identity_list, section: defaults} name: Default vault ids type: list yaml: {key: defaults.vault_identity_list}&lt;/pre&gt; &lt;p&gt;You can reference multiple vault IDs and their corresponding vault files in &lt;code&gt;ansible.cfg&lt;/code&gt;.  The &lt;code&gt;vault_identity_list&lt;/code&gt; key under the &lt;code&gt;default&lt;/code&gt; section is used to map the vault IDs to files.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;ansible.cfg&lt;/code&gt; has the following configuration:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ cat ansible.cfg [defaults] inventory = inventory remote_user = root vault_identity_list = inline@~/ansible/.inline_pass , files@~/ansible/.files_pass&lt;/pre&gt; &lt;p&gt;For the purpose of this article, I&amp;#8217;ve used the last line above to pre-create two vault password files in the &lt;code&gt;$HOME/ansible&lt;/code&gt; directory with the appropriate permissions. That last line maps vault-id &lt;code&gt;inline&lt;/code&gt; to &lt;code&gt;/home/sanujan/ansible/.inline_pass&lt;/code&gt; and vault-id &lt;code&gt;files&lt;/code&gt; to &lt;code&gt;/home/sanujan/ansible/.files_pass&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The contents of those password files are shown below:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ cat ~/ansible/.files_pass REDHAT [sanujan@fedora ansible]$ cat ~/ansible/.inline_pass redhat [sanujan@fedora ansible]$ ls -l ~/ansible/.files_pass ~/ansible/.inline_pass -r--------. 1 sanujan sanujan 7 Sep 23 06:25 /home/sanujan/ansible/.files_pass -r--------. 1 sanujan sanujan 7 Sep 23 06:25 /home/sanujan/ansible/.inline_pass&lt;/pre&gt; &lt;p&gt;This code creates a sample playbook containing encrypted text and a reference to an encrypted &lt;code&gt;vars&lt;/code&gt; file, (&lt;code&gt;vars/vars.yml&lt;/code&gt;), as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_667067" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667067" class="wp-image-667067" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Sample_Playbook_with_vault-300x103.png" alt="The results of running cat vault_encryption.yml." width="640" height="219" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Sample_Playbook_with_vault-300x103.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Sample_Playbook_with_vault-768x262.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Sample_Playbook_with_vault.png 998w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667067" class="wp-caption-text"&gt;Figure 1: Your playbook with its new encrypted vault contents.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;How the string and vars file are encrypted is detailed in the next section.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Encrypting a file to be included/referenced inside the playbook&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;To create the encrypted section for a file, run:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ ansible-vault encrypt --encrypt-vault-id files vars/vars.yml&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;--encrypt-vault-id files&lt;/code&gt; is how we reference the vault ID &amp;#8220;files&amp;#8221; to be used for encrypting the file &lt;code&gt;vars/vars.yml&lt;/code&gt; in the playbook directory. This command doesn&amp;#8217;t prompt us for a password because it references the ID &amp;#8220;files&amp;#8221; from &lt;code&gt;ansible.cfg&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The config file maps to &lt;code&gt;~/ansible/.files_pass&lt;/code&gt;, where the passphrase &lt;code&gt;REDHAT&lt;/code&gt; is hard-coded. In the &lt;code&gt;vars/vars.yml&lt;/code&gt; file, a variable is initialized with the key &lt;code&gt;course&lt;/code&gt; and value &lt;code&gt;DO457&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To view the encrypted file, you can use &lt;code&gt;ansible-vault&lt;/code&gt;&amp;#8216;s view option. Here, the passphrase is automatically taken by Ansible, as it&amp;#8217;s referenced inside &lt;code&gt;ansible.cfg&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ ansible-vault view vars/vars.yml  course: DO457&lt;/pre&gt; &lt;h2&gt;&lt;strong&gt;Encrypting a string to be used inside a playbook&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;To encrypt a string intended for use inside an Ansible playbook, use a format similar to:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ ansible-vault encrypt_string --encrypt-vault-id inline -n testing this-is-the-secret&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;--encrypt-vault-id inline&lt;/code&gt; portion is how we reference the vault ID &lt;code&gt;inline&lt;/code&gt; to be used for encrypting the string &lt;code&gt;this-is-the-secret&lt;/code&gt;. Next, we set the &lt;code&gt;testing&lt;/code&gt; variable to the value of &lt;code&gt;this-is-the-secret&lt;/code&gt;using &lt;code&gt;-n testing&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This command doesn&amp;#8217;t prompt us for a password. Instead, it references the ID &lt;code&gt;inline&lt;/code&gt; from &lt;code&gt;ansible.cfg,&lt;/code&gt; which maps to &lt;code&gt;~/ansible/.inline_pass&lt;/code&gt; with the passphrase &lt;code&gt;redhat&lt;/code&gt;. The results for this command are shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_667057" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667057" class="wp-image-667057" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/encrypt_string_output.png" alt="The results of running ansible-vault encrypt_string --encrypt-vault-id inline -n testing this-is-the-secret" width="640" height="105" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/encrypt_string_output.png 997w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/encrypt_string_output-300x49.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/encrypt_string_output-768x126.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667057" class="wp-caption-text"&gt;Figure 2: Encrypting a string to put in your Ansible playbook.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The output breaks down as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The variable name &lt;code&gt;testing&lt;/code&gt;, followed by &lt;code&gt;!vault |&lt;/code&gt;, indicates that the vault is encrypted.&lt;/li&gt; &lt;li&gt;The vault version that supports the vault ID is &lt;code&gt;1.2&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;The AES cipher in 256 bits is represented by &lt;code&gt;AES256&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;The vault ID in use is &lt;code&gt;inline&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The vault ID is visible in the header.&lt;/p&gt; &lt;p&gt;Now, you can copy and paste the contents including the variable name (&lt;code&gt;testing,&lt;/code&gt; in our case), all the way down to the line before &lt;code&gt;Encryption Successful&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Executing the playbook&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;In order to execute this playbook, run:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ ansible-playbook vault_encryption.yml&lt;/pre&gt; &lt;p&gt;The results are shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_667047" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667047" class="wp-image-667047" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/ansible_playbook_execution_output.png" alt="The results of running ansible-playbook vault_encryption.yml." width="640" height="172" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/ansible_playbook_execution_output.png 999w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/ansible_playbook_execution_output-300x80.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/ansible_playbook_execution_output-768x206.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667047" class="wp-caption-text"&gt;Figure 3: Executing your new playbook.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;strong&gt;Prompting the vault password during playbook execution&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;If the &lt;code&gt;vault_identity_list&lt;/code&gt; key is referenced in &lt;code&gt;ansible.cfg&lt;/code&gt;, Ansible will always read those password files from left to right, checking for possible passphrase matches and disregarding the vault IDs before the tilde (&lt;code&gt;~&lt;/code&gt;) character. If you prefer to have Ansible prompt you for the password to decrypt the vault string/file, you can comment out the &lt;code&gt;vault_identity_list&lt;/code&gt; key in &lt;code&gt;ansible.cfg&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;To execute the playbook while requiring a prompt, use &lt;code&gt;--vault-id id@prompt&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;[sanujan@fedora ansible]$ ansible-playbook --vault-id inline@prompt --vault-id files@prompt vault_encryption.yml&lt;/pre&gt; &lt;p&gt;An example is shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_667087" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667087" class="wp-image-667087" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_Prompt_Password.png" alt="The result of running ansible-playbook --vault-id inline@prompt --vault-id files@prompt vault_encryption.yml." width="640" height="202" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_Prompt_Password.png 999w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_Prompt_Password-300x95.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_Prompt_Password-768x242.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-667087" class="wp-caption-text"&gt;Figure 4: Being prompted while executing your new playbook.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As you can see, this command prompts you twice: once for entering the passphrase for vault ID &lt;code&gt;inline&lt;/code&gt; and the second for &lt;code&gt;files&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;Vault IDs in Ansible Tower&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Ansible Tower also supports vault IDs, starting with Tower 3.3. You can reference these vault IDs while creating a credential of type &lt;code&gt;Vault&lt;/code&gt;, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_667077" style="width: 660px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-667077" class="wp-image-667077" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_in_Tower.png" alt="The Ansible Tower New Credential screen." width="650" height="210" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_in_Tower.png 999w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_in_Tower-300x97.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/Vault_in_Tower-768x248.png 768w" sizes="(max-width: 650px) 100vw, 650px" /&gt;&lt;p id="caption-attachment-667077" class="wp-caption-text"&gt;Figure 5: Using Vault IDs in Ansible Tower.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Summary&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Vault IDs offer the flexibility to choose multiple passphrases for encrypting different files and strings.  Ansible Tower supports vault IDs also while creating the &lt;code&gt;Vault&lt;/code&gt; credential.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Learn more&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;To learn more about vault IDs and how to use them in Red Hat Ansible and Red Hat Ansible Tower, see the following resources:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/latest/user_guide/vault.html#vault-ids-and-multiple-vault-passwords" target="_blank" rel="noopener noreferrer"&gt;Ansible Vault ID&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible/latest/index.html" target="_blank" rel="noopener noreferrer"&gt;Ansible Documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://docs.ansible.com/ansible-tower/" target="_blank" rel="noopener noreferrer"&gt;Ansible Tower Documentation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#38;linkname=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F30%2Fvault-ids-in-red-hat-ansible-and-red-hat-ansible-tower%2F&amp;#038;title=Vault%20IDs%20in%20Red%20Hat%20Ansible%20and%20Red%20Hat%20Ansible%20Tower" data-a2a-url="https://developers.redhat.com/blog/2020/01/30/vault-ids-in-red-hat-ansible-and-red-hat-ansible-tower/" data-a2a-title="Vault IDs in Red Hat Ansible and Red Hat Ansible Tower"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/30/vault-ids-in-red-hat-ansible-and-red-hat-ansible-tower/"&gt;Vault IDs in Red Hat Ansible and Red Hat Ansible Tower&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FVKU_9xYZ-8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article demonstrates the use of multiple vault passwords through vault IDs. You will learn how to use vault IDs to encrypt a file and a string. Once they&amp;#8217;re encrypted, the vault ID can be referenced inside a playbook and used within Red Hat Ansible and Red Hat Ansible Tower. Starting with Ansible 2.4 and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/30/vault-ids-in-red-hat-ansible-and-red-hat-ansible-tower/"&gt;Vault IDs in Red Hat Ansible and Red Hat Ansible Tower&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">667017</post-id><dc:creator>Sreejith Anujan</dc:creator><dc:date>2020-01-30T08:00:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/30/vault-ids-in-red-hat-ansible-and-red-hat-ansible-tower/</feedburner:origLink></entry><entry><title>API login and JWT token generation using Keycloak</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DnOP0NklMI0/" /><category term="JavaScript" /><category term="Security" /><category term="Eclipse Che" /><category term="jwt token" /><category term="keycloak" /><category term="Red Hat SSO" /><category term="SSO" /><author><name>Muhammad Edwin</name></author><id>https://developers.redhat.com/blog/?p=670397</id><updated>2020-01-29T08:00:24Z</updated><published>2020-01-29T08:00:24Z</published><content type="html">&lt;p&gt;&lt;a href="https://www.redhat.com/en/products/middleware" target="_blank" rel="noopener noreferrer"&gt;Red Hat single sign-on&lt;/a&gt; (SSO)—or its open source version, Keycloak—is one of the leading products for web SSO capabilities, and is based on popular standards such as Security Assertion Markup Language (SAML) 2.0, OpenID Connect, and OAuth 2.0. One of Red Hat SSO&amp;#8217;s strongest features is that we can access Keycloak directly in many ways, whether through a simple HTML login form, or an API call. In the following scenario, we will generate a JWT token and then validate it. Everything will be done using API calls, so Keycloak&amp;#8217;s UI is not exposed to the public directly.&lt;/p&gt; &lt;h2&gt;&lt;span id="more-670397"&gt;&lt;/span&gt;Set up a user&lt;/h2&gt; &lt;p&gt;First, we will create a simple user in Keycloak, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_672877" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672877" class="wp-image-672877 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak01-1-1024x294.png" alt="Keycloak's user creation section." width="640" height="184" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak01-1-1024x294.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak01-1-300x86.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak01-1-768x220.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak01-1.png 1057w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672877" class="wp-caption-text"&gt;Figure 1: Create a user in Keycloak.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Fill in all mandatory fields, such as &lt;strong&gt;Username&lt;/strong&gt;, &lt;strong&gt;First Name&lt;/strong&gt;, and &lt;strong&gt;Last Name&lt;/strong&gt;, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_672887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672887" class="wp-image-672887" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak02-1.png" alt="The Keycloak Add user dialog box." width="640" height="527" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak02-1.png 716w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak02-1-300x247.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672887" class="wp-caption-text"&gt;Figure 2: Enter the user&amp;#8217;s information.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Set the user&amp;#8217;s password, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_672897" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672897" class="wp-image-672897" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak03-1.png" alt="The Keycloak Manage Password dialog box." width="639" height="341" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak03-1.png 866w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak03-1-300x160.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak03-1-768x410.png 768w" sizes="(max-width: 639px) 100vw, 639px" /&gt;&lt;p id="caption-attachment-672897" class="wp-caption-text"&gt;Figure 3: Set the user&amp;#8217;s password.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Set up a client&lt;/h2&gt; &lt;p&gt;The next step is to create a specific &lt;em&gt;client&lt;/em&gt; in our realm, as shown in Figure 4. A client in Keycloak represents a resource that particular users can access, whether for authenticating a user, requesting identity information, or validating an access token.&lt;/p&gt; &lt;div id="attachment_672907" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672907" class="wp-image-672907 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak04-1-1024x382.png" alt="The Keycloak Clients screen." width="640" height="239" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak04-1-1024x382.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak04-1-300x112.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak04-1-768x287.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak04-1.png 1273w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672907" class="wp-caption-text"&gt;Figure 4: View your existing clients.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click &lt;strong&gt;Create&lt;/strong&gt; to open the &lt;strong&gt;Add Client&lt;/strong&gt; dialog box, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_672917" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672917" class="wp-image-672917" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak05-1.png" alt="The Keycloak Add Client dialog box." width="640" height="344" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak05-1.png 703w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak05-1-300x161.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672917" class="wp-caption-text"&gt;Figure 5: Create a new client.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Fill in all of the mandatory fields in the client form. Pay attention, especially, to &lt;strong&gt;Direct Grant Flow&lt;/strong&gt; (shown in Figure 6) and set its value to &lt;strong&gt;direct grant&lt;/strong&gt;. Also, change &lt;strong&gt;Access Type&lt;/strong&gt; to &lt;strong&gt;confidential&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_672927" style="width: 606px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672927" class="wp-image-672927 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak06-1.png" alt="The Keycloak client Advanced Settings and Authentication Flow Overrides dialog box." width="596" height="466" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak06-1.png 596w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak06-1-300x235.png 300w" sizes="(max-width: 596px) 100vw, 596px" /&gt;&lt;p id="caption-attachment-672927" class="wp-caption-text"&gt;Figure 6: Overriding the client&amp;#8217;s authentication flow.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Finally, change the client&amp;#8217;s credentials in the &lt;strong&gt;Client Authenticator&lt;/strong&gt; field to &lt;strong&gt;Client Id and Secret&lt;/strong&gt;, as shown in Figure 7.&lt;/p&gt; &lt;div id="attachment_672937" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672937" class="wp-image-672937" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak07-1.png" alt="The Keycloak client's Credentials tab." width="640" height="215" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak07-1.png 995w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak07-1-300x101.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak07-1-768x258.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672937" class="wp-caption-text"&gt;Figure 7: Set your new client&amp;#8217;s credentials.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Test your new client&lt;/h2&gt; &lt;p&gt;Now we can test our newly created client through the REST API to simulate a simple login. Our authentication URL is:&lt;/p&gt; &lt;pre&gt;http://localhost:8080/auth/realms/&amp;#38;lt;your-realm-name&amp;#38;gt;/protocol/openid-connect/token&lt;/pre&gt; &lt;p&gt;Fill out the parameters and set our &lt;code&gt;client_id&lt;/code&gt; and &lt;code&gt;client_secret&lt;/code&gt; with our username and password:&lt;/p&gt; &lt;pre&gt;curl -L -X POST 'http://localhost:8080/auth/realms/whatever-realm/protocol/openid-connect/token' \ -H 'Content-Type: application/x-www-form-urlencoded' \ --data-urlencode 'client_id=clientid-03' \ --data-urlencode 'grant_type=password' \ --data-urlencode 'client_secret=ec78c6bb-8339-4bed-9b1b-e973d27107dc' \ --data-urlencode 'scope=openid' \ --data-urlencode 'username=emuhamma' \ --data-urlencode 'password=1'&lt;/pre&gt; &lt;p&gt;Or, we can use REST API tools like Postman to simulate an HTTP POST request, as shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_672947" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-672947" class="wp-image-672947" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak08-1.png" alt="" width="640" height="323" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak08-1.png 1010w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak08-1-300x151.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/keycloak08-1-768x388.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-672947" class="wp-caption-text"&gt;Figure 8: Our simulated HTTP POST request.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The result would be a valid JWT token:&lt;/p&gt; &lt;pre&gt;{ "access_token": "eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiAwNjEwLCJpc3MiOiJodHRwO.......wKRTus6PAoHMFlIlYQ75dYiLzzuRMvdXkHl6naLNQ8wYDv4gi7A3eJ163YzXSJf5PmQ", "expires_in": 600, "refresh_expires_in": 1800, "refresh_token": "eyJhbGciOiJIUzI1NiIsInR5cC.......IsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoib3BlbmlkIGVtYWlsIHByb2ZpbGUifQ.ePV2aqeDjlg6ih6SA7_x77gT4JYyv7HvK7PLQW-X1mM", "token_type": "bearer", "id_token": "eyJhbGciOiJSUz.......A_d_LV96VCLBeTJSpqeqpMJYlh4AMJqN6kddtrI4ixZLfwAIj-Qwqn9kzGe-v1-oe80wQXrXzVBG7TJbKm4x5bgCO_B9lnDMrey90rvaKKr48K697ug", "not-before-policy": 0, "session_state": "22c8278b-3346-468e-9533-f41f22ed264f", "scope": "openid email profile" }&lt;/pre&gt; &lt;p&gt;A wrong username and password combination results in an HTTP 401 response code and a response body like this:&lt;/p&gt; &lt;pre&gt;{ "error": "invalid_grant", "error_description": "Invalid user credentials" }&lt;/pre&gt; &lt;p&gt;There you go. Now you have a login API configured to work well with Keycloak. Have fun!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#38;linkname=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F29%2Fapi-login-and-jwt-token-generation-using-keycloak%2F&amp;#038;title=API%20login%20and%20JWT%20token%20generation%20using%20Keycloak" data-a2a-url="https://developers.redhat.com/blog/2020/01/29/api-login-and-jwt-token-generation-using-keycloak/" data-a2a-title="API login and JWT token generation using Keycloak"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/29/api-login-and-jwt-token-generation-using-keycloak/"&gt;API login and JWT token generation using Keycloak&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DnOP0NklMI0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat single sign-on (SSO)—or its open source version, Keycloak—is one of the leading products for web SSO capabilities, and is based on popular standards such as Security Assertion Markup Language (SAML) 2.0, OpenID Connect, and OAuth 2.0. One of Red Hat SSO&amp;#8217;s strongest features is that we can access Keycloak directly in many ways, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/29/api-login-and-jwt-token-generation-using-keycloak/"&gt;API login and JWT token generation using Keycloak&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">670397</post-id><dc:creator>Muhammad Edwin</dc:creator><dc:date>2020-01-29T08:00:24Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/29/api-login-and-jwt-token-generation-using-keycloak/</feedburner:origLink></entry><entry><title>How to Install Red Hat Process Automation Manager 7.6 in Minutes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/wGOcd7LnMnA/how-to-install-red-hat-process-automation-manager-76-in-minutes.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_process_automation_manager_7_6_in_minutes</id><updated>2020-01-29T06:00:11Z</updated><published>2020-01-29T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&amp;nbsp;&lt;a href="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s1600/rhpam-login.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-original-height="927" data-original-width="1600" height="185" src="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s320/rhpam-login.png" title="" width="320" /&gt;&lt;/a&gt;While you've seen the many &lt;a href="http://www.schabell.org/search/label/OpenShift" target="_blank"&gt;developer tooling articles&lt;/a&gt; where I've helped you to &lt;a href="https://gitlab.com/redhatdemocentral" target="_blank"&gt;get started on the OpenShift Container Platform&lt;/a&gt;, there is still a basic need to run our tooling locally on our own machine.&lt;br /&gt;&lt;br /&gt;With that in mind, here's an update that installs the latest version of open source process automation tooling for your development projects in just minutes on your very own machine.&lt;br /&gt;&lt;br /&gt;Not only that, it's done in just three easy steps and done in a few minutes!&lt;br /&gt;&lt;br /&gt;See if I'm telling the truth, let's install it now.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;Just three easy steps to a fully installed and configured Red Hat Process Automation manager.&lt;br /&gt;&lt;h2 data-sourcepos="6:1-8:122" dir="auto"&gt;Install on your machine&lt;/h2&gt;&lt;a href="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s1600/rhpam-business-central.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-original-height="935" data-original-width="1600" height="186" src="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s320/rhpam-business-central.png" title="" width="320" /&gt;&lt;/a&gt;There are a few component you'll need to download for free from the provided developers site, then obtain the project linked below, add the downloads, and run the installation script.&lt;br /&gt;&lt;br /&gt;Watch the installation unfold before your eyes, with configuration, settings, and user creation all detailed in the script output so you can learn from the installation.&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Give it a try with these three steps: &lt;br /&gt;&lt;ol data-sourcepos="8:1-17:0" style="text-align: left;"&gt;&lt;li data-sourcepos="8:1-9:0"&gt;&lt;div data-sourcepos="8:4-8:122"&gt;&lt;a href="https://gitlab.com/bpmworkshop/rhpam-install-demo/-/archive/master/rhpam-install-demo-master.zip"&gt;Download and unzip.&lt;/a&gt;&lt;/div&gt;&lt;div data-sourcepos="8:4-8:122"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="10:1-11:0"&gt;&lt;div data-sourcepos="10:4-10:81"&gt;Add products to installs directory, see installs/README for details and links.&lt;/div&gt;&lt;div data-sourcepos="10:4-10:81"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="14:1-15:0"&gt;&lt;div data-sourcepos="12:4-12:92"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges.&lt;/div&gt;&lt;div data-sourcepos="12:4-12:92"&gt;&lt;br /&gt;&lt;/div&gt;&amp;nbsp;Login to &lt;a href="http://localhost:8080/business-central" rel="nofollow noreferrer noopener" target="_blank"&gt;http://localhost:8080/business-central&lt;/a&gt; (u:erics / p:redhatpam1!)&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;That's it, not it's time to enjoy your installed and configured Red Hat Process Automation Manager.&lt;br /&gt;&lt;div&gt;&lt;br /&gt;Not sure how to get started with process automation? Try one of these &lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/3" rel=" noreferrer noopener" target="_blank"&gt;online workshops&lt;/a&gt; to build a first project from scratch.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=L5ChD1I3HUA:f4iLUSBG3lM:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=L5ChD1I3HUA:f4iLUSBG3lM:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=L5ChD1I3HUA:f4iLUSBG3lM:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=L5ChD1I3HUA:f4iLUSBG3lM:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=L5ChD1I3HUA:f4iLUSBG3lM:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/L5ChD1I3HUA" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/wGOcd7LnMnA" height="1" width="1" alt=""/&gt;</content><summary> While you've seen the many developer tooling articles where I've helped you to get started on the OpenShift Container Platform, there is still a basic need to run our tooling locally on our own machine. With that in mind, here's an update that installs the latest version of open source process automation tooling for your development projects in just minutes on your very own machine. Not only that...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-29T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/L5ChD1I3HUA/how-to-install-red-hat-process-automation-manager-76-in-minutes.html</feedburner:origLink></entry></feed>
